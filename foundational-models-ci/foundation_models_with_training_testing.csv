name,owner,url,stars,forks,description,topics,language,created_at,updated_at,has_training,training_files_sample,has_testing,testing_files_sample,open_issues,license
transformers,huggingface,https://github.com/huggingface/transformers,153668,31358,"ğŸ¤— Transformers: the model-definition framework for state-of-the-art machine learning models in text, vision, audio, and multimodal models, for both inference and training. ","['audio', 'deep-learning', 'deepseek', 'gemma', 'glm', 'hacktoberfest', 'llm', 'machine-learning', 'model-hub', 'natural-language-processing', 'nlp', 'pretrained-models', 'python', 'pytorch', 'pytorch-transformers', 'qwen', 'speech-recognition', 'transformer', 'vlm']",Python,2018-10-29T13:56:00Z,2025-12-10T05:13:19Z,True,"['docs/source/ar/trainer.md', 'docs/source/ar/training.md', 'docs/source/de/training.md', 'docs/source/en/hpo_train.md', 'docs/source/en/internal/trainer_utils.md']",True,"['.circleci/parse_test_outputs.py', '.github/workflows/benchmark_v2.yml', '.github/workflows/benchmark_v2_a10_caller.yml', '.github/workflows/benchmark_v2_mi325_caller.yml', '.github/workflows/check_failed_tests.yml']",2142,Apache License 2.0
funNLP,fighting41love,https://github.com/fighting41love/funNLP,77744,15091,"ä¸­è‹±æ–‡æ•æ„Ÿè¯ã€è¯­è¨€æ£€æµ‹ã€ä¸­å¤–æ‰‹æœº/ç”µè¯å½’å±åœ°/è¿è¥å•†æŸ¥è¯¢ã€åå­—æ¨æ–­æ€§åˆ«ã€æ‰‹æœºå·æŠ½å–ã€èº«ä»½è¯æŠ½å–ã€é‚®ç®±æŠ½å–ã€ä¸­æ—¥æ–‡äººååº“ã€ä¸­æ–‡ç¼©å†™åº“ã€æ‹†å­—è¯å…¸ã€è¯æ±‡æƒ…æ„Ÿå€¼ã€åœç”¨è¯ã€ååŠ¨è¯è¡¨ã€æš´æè¯è¡¨ã€ç¹ç®€ä½“è½¬æ¢ã€è‹±æ–‡æ¨¡æ‹Ÿä¸­æ–‡å‘éŸ³ã€æ±ªå³°æ­Œè¯ç”Ÿæˆå™¨ã€èŒä¸šåç§°è¯åº“ã€åŒä¹‰è¯åº“ã€åä¹‰è¯åº“ã€å¦å®šè¯åº“ã€æ±½è½¦å“ç‰Œè¯åº“ã€æ±½è½¦é›¶ä»¶è¯åº“ã€è¿ç»­è‹±æ–‡åˆ‡å‰²ã€å„ç§ä¸­æ–‡è¯å‘é‡ã€å…¬å¸åå­—å¤§å…¨ã€å¤è¯—è¯åº“ã€ITè¯åº“ã€è´¢ç»è¯åº“ã€æˆè¯­è¯åº“ã€åœ°åè¯åº“ã€å†å²åäººè¯åº“ã€è¯—è¯è¯åº“ã€åŒ»å­¦è¯åº“ã€é¥®é£Ÿè¯åº“ã€æ³•å¾‹è¯åº“ã€æ±½è½¦è¯åº“ã€åŠ¨ç‰©è¯åº“ã€ä¸­æ–‡èŠå¤©è¯­æ–™ã€ä¸­æ–‡è°£è¨€æ•°æ®ã€ç™¾åº¦ä¸­æ–‡é—®ç­”æ•°æ®é›†ã€å¥å­ç›¸ä¼¼åº¦åŒ¹é…ç®—æ³•é›†åˆã€bertèµ„æºã€æ–‡æœ¬ç”Ÿæˆ&æ‘˜è¦ç›¸å…³å·¥å…·ã€cocoNLPä¿¡æ¯æŠ½å–å·¥å…·ã€å›½å†…ç”µè¯å·ç æ­£åˆ™åŒ¹é…ã€æ¸…åå¤§å­¦XLORE:ä¸­è‹±æ–‡è·¨è¯­è¨€ç™¾ç§‘çŸ¥è¯†å›¾è°±ã€æ¸…åå¤§å­¦äººå·¥æ™ºèƒ½æŠ€æœ¯ç³»åˆ—æŠ¥å‘Šã€è‡ªç„¶è¯­è¨€ç”Ÿæˆã€NLUå¤ªéš¾äº†ç³»åˆ—ã€è‡ªåŠ¨å¯¹è”æ•°æ®åŠæœºå™¨äººã€ç”¨æˆ·åé»‘åå•åˆ—è¡¨ã€ç½ªåæ³•åŠ¡åè¯åŠåˆ†ç±»æ¨¡å‹ã€å¾®ä¿¡å…¬ä¼—å·è¯­æ–™ã€cs224næ·±åº¦å­¦ä¹ è‡ªç„¶è¯­è¨€å¤„ç†è¯¾ç¨‹ã€ä¸­æ–‡æ‰‹å†™æ±‰å­—è¯†åˆ«ã€ä¸­æ–‡è‡ªç„¶è¯­è¨€å¤„ç† è¯­æ–™/æ•°æ®é›†ã€å˜é‡å‘½åç¥å™¨ã€åˆ†è¯è¯­æ–™åº“+ä»£ç ã€ä»»åŠ¡å‹å¯¹è¯è‹±æ–‡æ•°æ®é›†ã€ASR è¯­éŸ³æ•°æ®é›† + åŸºäºæ·±åº¦å­¦ä¹ çš„ä¸­æ–‡è¯­éŸ³è¯†åˆ«ç³»ç»Ÿã€ç¬‘å£°æ£€æµ‹å™¨ã€Microsoftå¤šè¯­è¨€æ•°å­—/å•ä½/å¦‚æ—¥æœŸæ—¶é—´è¯†åˆ«åŒ…ã€ä¸­åæ–°åå­—å…¸æ•°æ®åº“åŠapi(åŒ…æ‹¬å¸¸ç”¨æ­‡åè¯­ã€æˆè¯­ã€è¯è¯­å’Œæ±‰å­—)ã€æ–‡æ¡£å›¾è°±è‡ªåŠ¨ç”Ÿæˆã€SpaCy ä¸­æ–‡æ¨¡å‹ã€Common Voiceè¯­éŸ³è¯†åˆ«æ•°æ®é›†æ–°ç‰ˆã€ç¥ç»ç½‘ç»œå…³ç³»æŠ½å–ã€åŸºäºbertçš„å‘½åå®ä½“è¯†åˆ«ã€å…³é”®è¯(Keyphrase)æŠ½å–åŒ…pkeã€åŸºäºåŒ»ç–—é¢†åŸŸçŸ¥è¯†å›¾è°±çš„é—®ç­”ç³»ç»Ÿã€åŸºäºä¾å­˜å¥æ³•ä¸è¯­ä¹‰è§’è‰²æ ‡æ³¨çš„äº‹ä»¶ä¸‰å…ƒç»„æŠ½å–ã€ä¾å­˜å¥æ³•åˆ†æ4ä¸‡å¥é«˜è´¨é‡æ ‡æ³¨æ•°æ®ã€cnocrï¼šç”¨æ¥åšä¸­æ–‡OCRçš„Python3åŒ…ã€ä¸­æ–‡äººç‰©å…³ç³»çŸ¥è¯†å›¾è°±é¡¹ç›®ã€ä¸­æ–‡nlpç«èµ›é¡¹ç›®åŠä»£ç æ±‡æ€»ã€ä¸­æ–‡å­—ç¬¦æ•°æ®ã€speech-aligner: ä»â€œäººå£°è¯­éŸ³â€åŠå…¶â€œè¯­è¨€æ–‡æœ¬â€äº§ç”ŸéŸ³ç´ çº§åˆ«æ—¶é—´å¯¹é½æ ‡æ³¨çš„å·¥å…·ã€AmpliGraph: çŸ¥è¯†å›¾è°±è¡¨ç¤ºå­¦ä¹ (Python)åº“ï¼šçŸ¥è¯†å›¾è°±æ¦‚å¿µé“¾æ¥é¢„æµ‹ã€Scattertext æ–‡æœ¬å¯è§†åŒ–(python)ã€è¯­è¨€/çŸ¥è¯†è¡¨ç¤ºå·¥å…·ï¼šBERT & ERNIEã€ä¸­æ–‡å¯¹æ¯”è‹±æ–‡è‡ªç„¶è¯­è¨€å¤„ç†NLPçš„åŒºåˆ«ç»¼è¿°ã€Synonymsä¸­æ–‡è¿‘ä¹‰è¯å·¥å…·åŒ…ã€HarvestTexté¢†åŸŸè‡ªé€‚åº”æ–‡æœ¬æŒ–æ˜å·¥å…·ï¼ˆæ–°è¯å‘ç°-æƒ…æ„Ÿåˆ†æ-å®ä½“é“¾æ¥ç­‰ï¼‰ã€word2wordï¼š(Python)æ–¹ä¾¿æ˜“ç”¨çš„å¤šè¯­è¨€è¯-è¯å¯¹é›†ï¼š62ç§è¯­è¨€/3,564ä¸ªå¤šè¯­è¨€å¯¹ã€è¯­éŸ³è¯†åˆ«è¯­æ–™ç”Ÿæˆå·¥å…·ï¼šä»å…·æœ‰éŸ³é¢‘/å­—å¹•çš„åœ¨çº¿è§†é¢‘åˆ›å»ºè‡ªåŠ¨è¯­éŸ³è¯†åˆ«(ASR)è¯­æ–™åº“ã€æ„å»ºåŒ»ç–—å®ä½“è¯†åˆ«çš„æ¨¡å‹ï¼ˆåŒ…å«è¯å…¸å’Œè¯­æ–™æ ‡æ³¨ï¼‰ã€å•æ–‡æ¡£éç›‘ç£çš„å…³é”®è¯æŠ½å–ã€Kashgariä¸­ä½¿ç”¨gpt-2è¯­è¨€æ¨¡å‹ã€å¼€æºçš„é‡‘èæŠ•èµ„æ•°æ®æå–å·¥å…·ã€æ–‡æœ¬è‡ªåŠ¨æ‘˜è¦åº“TextTeaser: ä»…æ”¯æŒè‹±æ–‡ã€äººæ°‘æ—¥æŠ¥è¯­æ–™å¤„ç†å·¥å…·é›†ã€ä¸€äº›å…³äºè‡ªç„¶è¯­è¨€çš„åŸºæœ¬æ¨¡å‹ã€åŸºäº14Wæ­Œæ›²çŸ¥è¯†åº“çš„é—®ç­”å°è¯•--åŠŸèƒ½åŒ…æ‹¬æ­Œè¯æ¥é¾™andå·²çŸ¥æ­Œè¯æ‰¾æ­Œæ›²ä»¥åŠæ­Œæ›²æ­Œæ‰‹æ­Œè¯ä¸‰è§’å…³ç³»çš„é—®ç­”ã€åŸºäºSiamese bilstmæ¨¡å‹çš„ç›¸ä¼¼å¥å­åˆ¤å®šæ¨¡å‹å¹¶æä¾›è®­ç»ƒæ•°æ®é›†å’Œæµ‹è¯•æ•°æ®é›†ã€ç”¨Transformerç¼–è§£ç æ¨¡å‹å®ç°çš„æ ¹æ®Hacker Newsæ–‡ç« æ ‡é¢˜è‡ªåŠ¨ç”Ÿæˆè¯„è®ºã€ç”¨BERTè¿›è¡Œåºåˆ—æ ‡è®°å’Œæ–‡æœ¬åˆ†ç±»çš„æ¨¡æ¿ä»£ç ã€LitBankï¼šNLPæ•°æ®é›†â€”â€”æ”¯æŒè‡ªç„¶è¯­è¨€å¤„ç†å’Œè®¡ç®—äººæ–‡å­¦ç§‘ä»»åŠ¡çš„100éƒ¨å¸¦æ ‡è®°è‹±æ–‡å°è¯´è¯­æ–™ã€ç™¾åº¦å¼€æºçš„åŸºå‡†ä¿¡æ¯æŠ½å–ç³»ç»Ÿã€è™šå‡æ–°é—»æ•°æ®é›†ã€Facebook: LAMAè¯­è¨€æ¨¡å‹åˆ†æï¼Œæä¾›Transformer-XL/BERT/ELMo/GPTé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„ç»Ÿä¸€è®¿é—®æ¥å£ã€CommonsenseQAï¼šé¢å‘å¸¸è¯†çš„è‹±æ–‡QAæŒ‘æˆ˜ã€ä¸­æ–‡çŸ¥è¯†å›¾è°±èµ„æ–™ã€æ•°æ®åŠå·¥å…·ã€å„å¤§å…¬å¸å†…éƒ¨é‡Œå¤§ç‰›åˆ†äº«çš„æŠ€æœ¯æ–‡æ¡£ PDF æˆ–è€… PPTã€è‡ªç„¶è¯­è¨€ç”ŸæˆSQLè¯­å¥ï¼ˆè‹±æ–‡ï¼‰ã€ä¸­æ–‡NLPæ•°æ®å¢å¼ºï¼ˆEDAï¼‰å·¥å…·ã€è‹±æ–‡NLPæ•°æ®å¢å¼ºå·¥å…· ã€åŸºäºåŒ»è¯çŸ¥è¯†å›¾è°±çš„æ™ºèƒ½é—®ç­”ç³»ç»Ÿã€äº¬ä¸œå•†å“çŸ¥è¯†å›¾è°±ã€åŸºäºmongodbå­˜å‚¨çš„å†›äº‹é¢†åŸŸçŸ¥è¯†å›¾è°±é—®ç­”é¡¹ç›®ã€åŸºäºè¿œç›‘ç£çš„ä¸­æ–‡å…³ç³»æŠ½å–ã€è¯­éŸ³æƒ…æ„Ÿåˆ†æã€ä¸­æ–‡ULMFiT-æƒ…æ„Ÿåˆ†æ-æ–‡æœ¬åˆ†ç±»-è¯­æ–™åŠæ¨¡å‹ã€ä¸€ä¸ªæ‹ç…§åšé¢˜ç¨‹åºã€ä¸–ç•Œå„å›½å¤§è§„æ¨¡äººååº“ã€ä¸€ä¸ªåˆ©ç”¨æœ‰è¶£ä¸­æ–‡è¯­æ–™åº“ qingyun è®­ç»ƒå‡ºæ¥çš„ä¸­æ–‡èŠå¤©æœºå™¨äººã€ä¸­æ–‡èŠå¤©æœºå™¨äººseqGANã€çœå¸‚åŒºé•‡è¡Œæ”¿åŒºåˆ’æ•°æ®å¸¦æ‹¼éŸ³æ ‡æ³¨ã€æ•™è‚²è¡Œä¸šæ–°é—»è¯­æ–™åº“åŒ…å«è‡ªåŠ¨æ–‡æ‘˜åŠŸèƒ½ã€å¼€æ”¾äº†å¯¹è¯æœºå™¨äºº-çŸ¥è¯†å›¾è°±-è¯­ä¹‰ç†è§£-è‡ªç„¶è¯­è¨€å¤„ç†å·¥å…·åŠæ•°æ®ã€ä¸­æ–‡çŸ¥è¯†å›¾è°±ï¼šåŸºäºç™¾åº¦ç™¾ç§‘ä¸­æ–‡é¡µé¢-æŠ½å–ä¸‰å…ƒç»„ä¿¡æ¯-æ„å»ºä¸­æ–‡çŸ¥è¯†å›¾è°±ã€masr: ä¸­æ–‡è¯­éŸ³è¯†åˆ«-æä¾›é¢„è®­ç»ƒæ¨¡å‹-é«˜è¯†åˆ«ç‡ã€PythonéŸ³é¢‘æ•°æ®å¢å¹¿åº“ã€ä¸­æ–‡å…¨è¯è¦†ç›–BERTåŠä¸¤ä»½é˜…è¯»ç†è§£æ•°æ®ã€ConvLabï¼šå¼€æºå¤šåŸŸç«¯åˆ°ç«¯å¯¹è¯ç³»ç»Ÿå¹³å°ã€ä¸­æ–‡è‡ªç„¶è¯­è¨€å¤„ç†æ•°æ®é›†ã€åŸºäºæœ€æ–°ç‰ˆæœ¬rasaæ­å»ºçš„å¯¹è¯ç³»ç»Ÿã€åŸºäºTensorFlowå’ŒBERTçš„ç®¡é“å¼å®ä½“åŠå…³ç³»æŠ½å–ã€ä¸€ä¸ªå°å‹çš„è¯åˆ¸çŸ¥è¯†å›¾è°±/çŸ¥è¯†åº“ã€å¤ç›˜æ‰€æœ‰NLPæ¯”èµ›çš„TOPæ–¹æ¡ˆã€OpenCLaPï¼šå¤šé¢†åŸŸå¼€æºä¸­æ–‡é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ä»“åº“ã€UERï¼šåŸºäºä¸åŒè¯­æ–™+ç¼–ç å™¨+ç›®æ ‡ä»»åŠ¡çš„ä¸­æ–‡é¢„è®­ç»ƒæ¨¡å‹ä»“åº“ã€ä¸­æ–‡è‡ªç„¶è¯­è¨€å¤„ç†å‘é‡åˆé›†ã€åŸºäºé‡‘è-å¸æ³•é¢†åŸŸ(å…¼æœ‰é—²èŠæ€§è´¨)çš„èŠå¤©æœºå™¨äººã€g2pCï¼šåŸºäºä¸Šä¸‹æ–‡çš„æ±‰è¯­è¯»éŸ³è‡ªåŠ¨æ ‡è®°æ¨¡å—ã€Zincbase çŸ¥è¯†å›¾è°±æ„å»ºå·¥å…·åŒ…ã€è¯—æ­Œè´¨é‡è¯„ä»·/ç»†ç²’åº¦æƒ…æ„Ÿè¯—æ­Œè¯­æ–™åº“ã€å¿«é€Ÿè½¬åŒ–ã€Œä¸­æ–‡æ•°å­—ã€å’Œã€Œé˜¿æ‹‰ä¼¯æ•°å­—ã€ã€ç™¾åº¦çŸ¥é“é—®ç­”è¯­æ–™åº“ã€åŸºäºçŸ¥è¯†å›¾è°±çš„é—®ç­”ç³»ç»Ÿã€jieba_fast åŠ é€Ÿç‰ˆçš„jiebaã€æ­£åˆ™è¡¨è¾¾å¼æ•™ç¨‹ã€ä¸­æ–‡é˜…è¯»ç†è§£æ•°æ®é›†ã€åŸºäºBERTç­‰æœ€æ–°è¯­è¨€æ¨¡å‹çš„æŠ½å–å¼æ‘˜è¦æå–ã€Pythonåˆ©ç”¨æ·±åº¦å­¦ä¹ è¿›è¡Œæ–‡æœ¬æ‘˜è¦çš„ç»¼åˆæŒ‡å—ã€çŸ¥è¯†å›¾è°±æ·±åº¦å­¦ä¹ ç›¸å…³èµ„æ–™æ•´ç†ã€ç»´åŸºå¤§è§„æ¨¡å¹³è¡Œæ–‡æœ¬è¯­æ–™ã€StanfordNLP 0.2.0ï¼šçº¯Pythonç‰ˆè‡ªç„¶è¯­è¨€å¤„ç†åŒ…ã€NeuralNLP-NeuralClassifierï¼šè…¾è®¯å¼€æºæ·±åº¦å­¦ä¹ æ–‡æœ¬åˆ†ç±»å·¥å…·ã€ç«¯åˆ°ç«¯çš„å°é—­åŸŸå¯¹è¯ç³»ç»Ÿã€ä¸­æ–‡å‘½åå®ä½“è¯†åˆ«ï¼šNeuroNER vs. BertNERã€æ–°é—»äº‹ä»¶çº¿ç´¢æŠ½å–ã€2019å¹´ç™¾åº¦çš„ä¸‰å…ƒç»„æŠ½å–æ¯”èµ›ï¼šâ€œç§‘å­¦ç©ºé—´é˜Ÿâ€æºç ã€åŸºäºä¾å­˜å¥æ³•çš„å¼€æ”¾åŸŸæ–‡æœ¬çŸ¥è¯†ä¸‰å…ƒç»„æŠ½å–å’ŒçŸ¥è¯†åº“æ„å»ºã€ä¸­æ–‡çš„GPT2è®­ç»ƒä»£ç ã€ML-NLP - æœºå™¨å­¦ä¹ (Machine Learning)NLPé¢è¯•ä¸­å¸¸è€ƒåˆ°çš„çŸ¥è¯†ç‚¹å’Œä»£ç å®ç°ã€nlp4han:ä¸­æ–‡è‡ªç„¶è¯­è¨€å¤„ç†å·¥å…·é›†(æ–­å¥/åˆ†è¯/è¯æ€§æ ‡æ³¨/ç»„å—/å¥æ³•åˆ†æ/è¯­ä¹‰åˆ†æ/NER/Nå…ƒè¯­æ³•/HMM/ä»£è¯æ¶ˆè§£/æƒ…æ„Ÿåˆ†æ/æ‹¼å†™æ£€æŸ¥ã€XLMï¼šFacebookçš„è·¨è¯­è¨€é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ã€ç”¨åŸºäºBERTçš„å¾®è°ƒå’Œç‰¹å¾æå–æ–¹æ³•æ¥è¿›è¡ŒçŸ¥è¯†å›¾è°±ç™¾åº¦ç™¾ç§‘äººç‰©è¯æ¡å±æ€§æŠ½å–ã€ä¸­æ–‡è‡ªç„¶è¯­è¨€å¤„ç†ç›¸å…³çš„å¼€æ”¾ä»»åŠ¡-æ•°æ®é›†-å½“å‰æœ€ä½³ç»“æœã€CoupletAI - åŸºäºCNN+Bi-LSTM+Attention çš„è‡ªåŠ¨å¯¹å¯¹è”ç³»ç»Ÿã€æŠ½è±¡çŸ¥è¯†å›¾è°±ã€MiningZhiDaoQACorpus - 580ä¸‡ç™¾åº¦çŸ¥é“é—®ç­”æ•°æ®æŒ–æ˜é¡¹ç›®ã€brat rapid annotation tool: åºåˆ—æ ‡æ³¨å·¥å…·ã€å¤§è§„æ¨¡ä¸­æ–‡çŸ¥è¯†å›¾è°±æ•°æ®ï¼š1.4äº¿å®ä½“ã€æ•°æ®å¢å¼ºåœ¨æœºå™¨ç¿»è¯‘åŠå…¶ä»–nlpä»»åŠ¡ä¸­çš„åº”ç”¨åŠæ•ˆæœã€allennlpé˜…è¯»ç†è§£:æ”¯æŒå¤šç§æ•°æ®å’Œæ¨¡å‹ã€PDFè¡¨æ ¼æ•°æ®æå–å·¥å…· ã€ Graphbrainï¼šAIå¼€æºè½¯ä»¶åº“å’Œç§‘ç ”å·¥å…·ï¼Œç›®çš„æ˜¯ä¿ƒè¿›è‡ªåŠ¨æ„ä¹‰æå–å’Œæ–‡æœ¬ç†è§£ä»¥åŠçŸ¥è¯†çš„æ¢ç´¢å’Œæ¨æ–­ã€ç®€å†è‡ªåŠ¨ç­›é€‰ç³»ç»Ÿã€åŸºäºå‘½åå®ä½“è¯†åˆ«çš„ç®€å†è‡ªåŠ¨æ‘˜è¦ã€ä¸­æ–‡è¯­è¨€ç†è§£æµ‹è¯„åŸºå‡†ï¼ŒåŒ…æ‹¬ä»£è¡¨æ€§çš„æ•°æ®é›†&åŸºå‡†æ¨¡å‹&è¯­æ–™åº“&æ’è¡Œæ¦œã€æ ‘æ´ OCR æ–‡å­—è¯†åˆ« ã€ä»åŒ…å«è¡¨æ ¼çš„æ‰«æå›¾ç‰‡ä¸­è¯†åˆ«è¡¨æ ¼å’Œæ–‡å­—ã€è¯­å£°è¿ç§»ã€Pythonå£è¯­è‡ªç„¶è¯­è¨€å¤„ç†å·¥å…·é›†(è‹±æ–‡)ã€ similarityï¼šç›¸ä¼¼åº¦è®¡ç®—å·¥å…·åŒ…ï¼Œjavaç¼–å†™ã€æµ·é‡ä¸­æ–‡é¢„è®­ç»ƒALBERTæ¨¡å‹ ã€Transformers 2.0 ã€åŸºäºå¤§è§„æ¨¡éŸ³é¢‘æ•°æ®é›†Audiosetçš„éŸ³é¢‘å¢å¼º ã€Poplarï¼šç½‘é¡µç‰ˆè‡ªç„¶è¯­è¨€æ ‡æ³¨å·¥å…·ã€å›¾ç‰‡æ–‡å­—å»é™¤ï¼Œå¯ç”¨äºæ¼«ç”»ç¿»è¯‘ ã€186ç§è¯­è¨€çš„æ•°å­—å«æ³•åº“ã€Amazonå‘å¸ƒåŸºäºçŸ¥è¯†çš„äºº-äººå¼€æ”¾é¢†åŸŸå¯¹è¯æ•°æ®é›† ã€ä¸­æ–‡æ–‡æœ¬çº é”™æ¨¡å—ä»£ç ã€ç¹ç®€ä½“è½¬æ¢ ã€ Pythonå®ç°çš„å¤šç§æ–‡æœ¬å¯è¯»æ€§è¯„ä»·æŒ‡æ ‡ã€ç±»ä¼¼äºäººå/åœ°å/ç»„ç»‡æœºæ„åçš„å‘½åä½“è¯†åˆ«æ•°æ®é›† ã€ä¸œå—å¤§å­¦ã€ŠçŸ¥è¯†å›¾è°±ã€‹ç ”ç©¶ç”Ÿè¯¾ç¨‹(èµ„æ–™)ã€. è‹±æ–‡æ‹¼å†™æ£€æŸ¥åº“ ã€ wwsearchæ˜¯ä¼ä¸šå¾®ä¿¡åå°è‡ªç ”çš„å…¨æ–‡æ£€ç´¢å¼•æ“ã€CHAMELEONï¼šæ·±åº¦å­¦ä¹ æ–°é—»æ¨èç³»ç»Ÿå…ƒæ¶æ„ ã€ 8ç¯‡è®ºæ–‡æ¢³ç†BERTç›¸å…³æ¨¡å‹è¿›å±•ä¸åæ€ã€DocSearchï¼šå…è´¹æ–‡æ¡£æœç´¢å¼•æ“ã€ LIDAï¼šè½»é‡äº¤äº’å¼å¯¹è¯æ ‡æ³¨å·¥å…· ã€aili - the fastest in-memory index in the East ä¸œåŠçƒæœ€å¿«å¹¶å‘ç´¢å¼• ã€çŸ¥è¯†å›¾è°±è½¦éŸ³å·¥ä½œé¡¹ç›®ã€è‡ªç„¶è¯­è¨€ç”Ÿæˆèµ„æºå¤§å…¨ ã€ä¸­æ—¥éŸ©åˆ†è¯åº“mecabçš„Pythonæ¥å£åº“ã€ä¸­æ–‡æ–‡æœ¬æ‘˜è¦/å…³é”®è¯æå–ã€æ±‰å­—å­—ç¬¦ç‰¹å¾æå–å™¨ (featurizer)ï¼Œæå–æ±‰å­—çš„ç‰¹å¾ï¼ˆå‘éŸ³ç‰¹å¾ã€å­—å½¢ç‰¹å¾ï¼‰ç”¨åšæ·±åº¦å­¦ä¹ çš„ç‰¹å¾ã€ä¸­æ–‡ç”Ÿæˆä»»åŠ¡åŸºå‡†æµ‹è¯„ ã€ä¸­æ–‡ç¼©å†™æ•°æ®é›†ã€ä¸­æ–‡ä»»åŠ¡åŸºå‡†æµ‹è¯„ - ä»£è¡¨æ€§çš„æ•°æ®é›†-åŸºå‡†(é¢„è®­ç»ƒ)æ¨¡å‹-è¯­æ–™åº“-baseline-å·¥å…·åŒ…-æ’è¡Œæ¦œã€PySS3ï¼šé¢å‘å¯è§£é‡ŠAIçš„SS3æ–‡æœ¬åˆ†ç±»å™¨æœºå™¨å¯è§†åŒ–å·¥å…· ã€ä¸­æ–‡NLPæ•°æ®é›†åˆ—è¡¨ã€COPE - æ ¼å¾‹è¯—ç¼–è¾‘ç¨‹åºã€doccanoï¼šåŸºäºç½‘é¡µçš„å¼€æºååŒå¤šè¯­è¨€æ–‡æœ¬æ ‡æ³¨å·¥å…· ã€PreNLPï¼šè‡ªç„¶è¯­è¨€é¢„å¤„ç†åº“ã€ç®€å•çš„ç®€å†è§£æå™¨ï¼Œç”¨æ¥ä»ç®€å†ä¸­æå–å…³é”®ä¿¡æ¯ã€ç”¨äºä¸­æ–‡é—²èŠçš„GPT2æ¨¡å‹ï¼šGPT2-chitchatã€åŸºäºæ£€ç´¢èŠå¤©æœºå™¨äººå¤šè½®å“åº”é€‰æ‹©ç›¸å…³èµ„æºåˆ—è¡¨(Leaderboardsã€Datasetsã€Papers)ã€(Colab)æŠ½è±¡æ–‡æœ¬æ‘˜è¦å®ç°é›†é”¦(æ•™ç¨‹ ã€è¯è¯­æ‹¼éŸ³æ•°æ®ã€é«˜æ•ˆæ¨¡ç³Šæœç´¢å·¥å…·ã€NLPæ•°æ®å¢å¹¿èµ„æºé›†ã€å¾®è½¯å¯¹è¯æœºå™¨äººæ¡†æ¶ ã€ GitHub Typo Corpusï¼šå¤§è§„æ¨¡GitHubå¤šè¯­è¨€æ‹¼å†™é”™è¯¯/è¯­æ³•é”™è¯¯æ•°æ®é›†ã€TextClusterï¼šçŸ­æ–‡æœ¬èšç±»é¢„å¤„ç†æ¨¡å— Short text clusterã€é¢å‘è¯­éŸ³è¯†åˆ«çš„ä¸­æ–‡æ–‡æœ¬è§„èŒƒåŒ–ã€BLINKï¼šæœ€å…ˆè¿›çš„å®ä½“é“¾æ¥åº“ã€BertPuncï¼šåŸºäºBERTçš„æœ€å…ˆè¿›æ ‡ç‚¹ä¿®å¤æ¨¡å‹ã€Tokenizerï¼šå¿«é€Ÿã€å¯å®šåˆ¶çš„æ–‡æœ¬è¯æ¡åŒ–åº“ã€ä¸­æ–‡è¯­è¨€ç†è§£æµ‹è¯„åŸºå‡†ï¼ŒåŒ…æ‹¬ä»£è¡¨æ€§çš„æ•°æ®é›†ã€åŸºå‡†(é¢„è®­ç»ƒ)æ¨¡å‹ã€è¯­æ–™åº“ã€æ’è¡Œæ¦œã€spaCy åŒ»å­¦æ–‡æœ¬æŒ–æ˜ä¸ä¿¡æ¯æå– ã€ NLPä»»åŠ¡ç¤ºä¾‹é¡¹ç›®ä»£ç é›†ã€ pythonæ‹¼å†™æ£€æŸ¥åº“ã€chatbot-list - è¡Œä¸šå†…å…³äºæ™ºèƒ½å®¢æœã€èŠå¤©æœºå™¨äººçš„åº”ç”¨å’Œæ¶æ„ã€ç®—æ³•åˆ†äº«å’Œä»‹ç»ã€è¯­éŸ³è´¨é‡è¯„ä»·æŒ‡æ ‡(MOSNet, BSSEval, STOI, PESQ, SRMR)ã€ ç”¨138GBè¯­æ–™è®­ç»ƒçš„æ³•æ–‡RoBERTaé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ ã€BERT-NER-Pytorchï¼šä¸‰ç§ä¸åŒæ¨¡å¼çš„BERTä¸­æ–‡NERå®éªŒã€æ— é“è¯å…¸ - æœ‰é“è¯å…¸çš„å‘½ä»¤è¡Œç‰ˆæœ¬ï¼Œæ”¯æŒè‹±æ±‰äº’æŸ¥å’Œåœ¨çº¿æŸ¥è¯¢ã€2019å¹´NLPäº®ç‚¹å›é¡¾ã€ Chinese medical dialogue data ä¸­æ–‡åŒ»ç–—å¯¹è¯æ•°æ®é›† ã€æœ€å¥½çš„æ±‰å­—æ•°å­—(ä¸­æ–‡æ•°å­—)-é˜¿æ‹‰ä¼¯æ•°å­—è½¬æ¢å·¥å…·ã€ åŸºäºç™¾ç§‘çŸ¥è¯†åº“çš„ä¸­æ–‡è¯è¯­å¤šè¯ä¹‰/ä¹‰é¡¹è·å–ä¸ç‰¹å®šå¥å­è¯è¯­è¯­ä¹‰æ¶ˆæ­§ã€awesome-nlp-sentiment-analysis - æƒ…æ„Ÿåˆ†æã€æƒ…ç»ªåŸå› è¯†åˆ«ã€è¯„ä»·å¯¹è±¡å’Œè¯„ä»·è¯æŠ½å–ã€LineFlowï¼šé¢å‘æ‰€æœ‰æ·±åº¦å­¦ä¹ æ¡†æ¶çš„NLPæ•°æ®é«˜æ•ˆåŠ è½½å™¨ã€ä¸­æ–‡åŒ»å­¦NLPå…¬å¼€èµ„æºæ•´ç† ã€MedQuADï¼š(è‹±æ–‡)åŒ»å­¦é—®ç­”æ•°æ®é›†ã€å°†è‡ªç„¶è¯­è¨€æ•°å­—ä¸²è§£æè½¬æ¢ä¸ºæ•´æ•°å’Œæµ®ç‚¹æ•°ã€Transfer Learning in Natural Language Processing (NLP) ã€é¢å‘è¯­éŸ³è¯†åˆ«çš„ä¸­æ–‡/è‹±æ–‡å‘éŸ³è¾å…¸ã€Tokenizersï¼šæ³¨é‡æ€§èƒ½ä¸å¤šåŠŸèƒ½æ€§çš„æœ€å…ˆè¿›åˆ†è¯å™¨ã€CLUENER ç»†ç²’åº¦å‘½åå®ä½“è¯†åˆ« Fine Grained Named Entity Recognitionã€ åŸºäºBERTçš„ä¸­æ–‡å‘½åå®ä½“è¯†åˆ«ã€ä¸­æ–‡è°£è¨€æ•°æ®åº“ã€NLPæ•°æ®é›†/åŸºå‡†ä»»åŠ¡å¤§åˆ—è¡¨ã€nlpç›¸å…³çš„ä¸€äº›è®ºæ–‡åŠä»£ç , åŒ…æ‹¬ä¸»é¢˜æ¨¡å‹ã€è¯å‘é‡(Word Embedding)ã€å‘½åå®ä½“è¯†åˆ«(NER)ã€æ–‡æœ¬åˆ†ç±»(Text Classificatin)ã€æ–‡æœ¬ç”Ÿæˆ(Text Generation)ã€æ–‡æœ¬ç›¸ä¼¼æ€§(Text Similarity)è®¡ç®—ç­‰ï¼Œæ¶‰åŠåˆ°å„ç§ä¸nlpç›¸å…³çš„ç®—æ³•ï¼ŒåŸºäºkeraså’Œtensorflow ã€Pythonæ–‡æœ¬æŒ–æ˜/NLPå®æˆ˜ç¤ºä¾‹ã€ Blackstoneï¼šé¢å‘éç»“æ„åŒ–æ³•å¾‹æ–‡æœ¬çš„spaCy pipelineå’ŒNLPæ¨¡å‹é€šè¿‡åŒä¹‰è¯æ›¿æ¢å®ç°æ–‡æœ¬â€œå˜è„¸â€ ã€ä¸­æ–‡ é¢„è®­ç»ƒ ELECTREA æ¨¡å‹: åŸºäºå¯¹æŠ—å­¦ä¹  pretrain Chinese Model ã€albert-chinese-ner - ç”¨é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ALBERTåšä¸­æ–‡NER ã€åŸºäºGPT2çš„ç‰¹å®šä¸»é¢˜æ–‡æœ¬ç”Ÿæˆ/æ–‡æœ¬å¢å¹¿ã€å¼€æºé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹åˆé›†ã€å¤šè¯­è¨€å¥å‘é‡åŒ…ã€ç¼–ç ã€æ ‡è®°å’Œå®ç°ï¼šä¸€ç§å¯æ§é«˜æ•ˆçš„æ–‡æœ¬ç”Ÿæˆæ–¹æ³•ã€ è‹±æ–‡è„è¯å¤§åˆ—è¡¨ ã€attnvisï¼šGPT2ã€BERTç­‰transformerè¯­è¨€æ¨¡å‹æ³¨æ„åŠ›äº¤äº’å¯è§†åŒ–ã€CoVoSTï¼šFacebookå‘å¸ƒçš„å¤šè¯­ç§è¯­éŸ³-æ–‡æœ¬ç¿»è¯‘è¯­æ–™åº“ï¼ŒåŒ…æ‹¬11ç§è¯­è¨€(æ³•è¯­ã€å¾·è¯­ã€è·å…°è¯­ã€ä¿„è¯­ã€è¥¿ç­ç‰™è¯­ã€æ„å¤§åˆ©è¯­ã€åœŸè€³å…¶è¯­ã€æ³¢æ–¯è¯­ã€ç‘å…¸è¯­ã€è’™å¤è¯­å’Œä¸­æ–‡)çš„è¯­éŸ³ã€æ–‡å­—è½¬å½•åŠè‹±æ–‡è¯‘æ–‡ã€Jiaguè‡ªç„¶è¯­è¨€å¤„ç†å·¥å…· - ä»¥BiLSTMç­‰æ¨¡å‹ä¸ºåŸºç¡€ï¼Œæä¾›çŸ¥è¯†å›¾è°±å…³ç³»æŠ½å– ä¸­æ–‡åˆ†è¯ è¯æ€§æ ‡æ³¨ å‘½åå®ä½“è¯†åˆ« æƒ…æ„Ÿåˆ†æ æ–°è¯å‘ç° å…³é”®è¯ æ–‡æœ¬æ‘˜è¦ æ–‡æœ¬èšç±»ç­‰åŠŸèƒ½ã€ç”¨unetå®ç°å¯¹æ–‡æ¡£è¡¨æ ¼çš„è‡ªåŠ¨æ£€æµ‹ï¼Œè¡¨æ ¼é‡å»ºã€NLPäº‹ä»¶æå–æ–‡çŒ®èµ„æºåˆ—è¡¨ ã€ é‡‘èé¢†åŸŸè‡ªç„¶è¯­è¨€å¤„ç†ç ”ç©¶èµ„æºå¤§åˆ—è¡¨ã€CLUEDatasetSearch - ä¸­è‹±æ–‡NLPæ•°æ®é›†ï¼šæœç´¢æ‰€æœ‰ä¸­æ–‡NLPæ•°æ®é›†ï¼Œé™„å¸¸ç”¨è‹±æ–‡NLPæ•°æ®é›† ã€medical_NER - ä¸­æ–‡åŒ»å­¦çŸ¥è¯†å›¾è°±å‘½åå®ä½“è¯†åˆ« ã€(å“ˆä½›)è®²å› æœæ¨ç†çš„å…è´¹ä¹¦ã€çŸ¥è¯†å›¾è°±ç›¸å…³å­¦ä¹ èµ„æ–™/æ•°æ®é›†/å·¥å…·èµ„æºå¤§åˆ—è¡¨ã€Forteï¼šçµæ´»å¼ºå¤§çš„è‡ªç„¶è¯­è¨€å¤„ç†pipelineå·¥å…·é›† ã€Pythonå­—ç¬¦ä¸²ç›¸ä¼¼æ€§ç®—æ³•åº“ã€PyLaiaï¼šé¢å‘æ‰‹å†™æ–‡æ¡£åˆ†æçš„æ·±åº¦å­¦ä¹ å·¥å…·åŒ…ã€TextFoolerï¼šé’ˆå¯¹æ–‡æœ¬åˆ†ç±»/æ¨ç†çš„å¯¹æŠ—æ–‡æœ¬ç”Ÿæˆæ¨¡å—ã€Haystackï¼šçµæ´»ã€å¼ºå¤§çš„å¯æ‰©å±•é—®ç­”(QA)æ¡†æ¶ã€ä¸­æ–‡å…³é”®çŸ­è¯­æŠ½å–å·¥å…·",[],Python,2018-08-21T11:20:39Z,2025-12-10T04:39:53Z,True,"['data/ä¸­æ–‡ç¼©å†™åº“/train_set.txt', 'data/ä¸­æ–‡ç¼©å†™åº“/train_set.txt']",True,['data/ä¸­æ–‡ç¼©å†™åº“/test_set.txt'],43,Unknown
vllm,vllm-project,https://github.com/vllm-project/vllm,65012,11851,A high-throughput and memory-efficient inference and serving engine for LLMs,"['amd', 'blackwell', 'cuda', 'deepseek', 'deepseek-v3', 'gpt', 'gpt-oss', 'inference', 'kimi', 'llama', 'llm', 'llm-serving', 'model-serving', 'moe', 'openai', 'pytorch', 'qwen', 'qwen3', 'tpu', 'transformer']",Python,2023-02-09T11:23:20Z,2025-12-10T05:17:52Z,True,"['docs/training/rlhf.md', 'docs/training/trl.md']",True,"['.buildkite/lm-eval-harness/conftest.py', '.buildkite/lm-eval-harness/test_lm_eval_correctness.py', '.buildkite/performance-benchmarks/tests/genai-perf-tests.json', '.buildkite/performance-benchmarks/tests/latency-tests-cpu.json', '.buildkite/performance-benchmarks/tests/latency-tests-hpu.json']",3136,Apache License 2.0
pytorch-image-models,huggingface,https://github.com/huggingface/pytorch-image-models,35974,5082,"The largest collection of PyTorch image encoders / backbones. Including train, eval, inference, export scripts, and pretrained weights -- ResNet, ResNeXT, EfficientNet, NFNet, Vision Transformer (ViT), MobileNetV4, MobileNet-V3 & V2, RegNet, DPN, CSPNet, Swin Transformer, MaxViT, CoAtNet, ConvNeXt, and more","['augmix', 'convnext', 'distributed-training', 'efficientnet', 'image-classification', 'imagenet', 'maxvit', 'mixnet', 'mobile-deep-learning', 'mobilenet-v2', 'mobilenetv3', 'nfnets', 'normalization-free-training', 'optimizer', 'pretrained-models', 'pretrained-weights', 'pytorch', 'randaugment', 'resnet', 'vision-transformer-models']",Python,2019-02-02T05:51:12Z,2025-12-10T04:56:40Z,True,"['distributed_train.sh', 'hfdocs/source/training_script.mdx', 'hfdocs/source/training_script.mdx', 'results/benchmark-train-amp-nchw-pt112-cu113-rtx3090.csv', 'results/benchmark-train-amp-nhwc-pt112-cu113-rtx3090.csv']",True,"['.github/workflows/tests.yml', 'tests/__init__.py', 'tests/test_layers.py', 'tests/test_layers_drop.py', 'tests/test_layers_pool.py']",72,Apache License 2.0
mmdetection,open-mmlab,https://github.com/open-mmlab/mmdetection,32143,9828,OpenMMLab Detection Toolbox and Benchmark,"['cascade-rcnn', 'convnext', 'detr', 'fast-rcnn', 'faster-rcnn', 'glip', 'grounding-dino', 'instance-segmentation', 'mask-rcnn', 'object-detection', 'panoptic-segmentation', 'pytorch', 'retinanet', 'rtmdet', 'semisupervised-learning', 'ssd', 'swin-transformer', 'transformer', 'vision-transformer', 'yolo']",Python,2018-08-22T07:06:06Z,2025-12-09T13:47:45Z,True,"['.dev_scripts/batch_train_list.txt', '.dev_scripts/batch_train_list.txt', '.dev_scripts/benchmark_train.py', '.dev_scripts/benchmark_train.py', '.dev_scripts/benchmark_train_models.txt']",True,"['.circleci/test.yml', '.dev_scripts/batch_test_list.py', '.dev_scripts/benchmark_filter.py', '.dev_scripts/benchmark_full_models.txt', '.dev_scripts/benchmark_inference_fps.py']",1944,Apache License 2.0
vit-pytorch,lucidrains,https://github.com/lucidrains/vit-pytorch,24616,3459,"Implementation of Vision Transformer, a simple way to achieve SOTA in vision classification with only a single transformer encoder, in Pytorch","['artificial-intelligence', 'attention-mechanism', 'computer-vision', 'image-classification', 'transformers']",Python,2020-10-03T22:47:24Z,2025-12-10T04:25:51Z,True,"['train_vit_decorr.py', 'train_vit_decorr.py']",True,"['.github/workflows/python-test.yml', 'tests/.ds_store', 'tests/test_vit.py']",142,MIT License
minGPT,karpathy,https://github.com/karpathy/minGPT,23117,3029,A minimal PyTorch re-implementation of the OpenAI GPT (Generative Pretrained Transformer) training,[],Python,2020-08-17T07:08:48Z,2025-12-10T03:49:11Z,True,['mingpt/trainer.py'],True,['tests/test_huggingface_import.py'],79,MIT License
sglang,sgl-project,https://github.com/sgl-project/sglang,21112,3681,SGLang is a fast serving framework for large language models and vision language models.,"['blackwell', 'cuda', 'deepseek', 'deepseek-r1', 'deepseek-v3', 'deepseek-v3-2', 'gpt-oss', 'inference', 'kimi', 'llama', 'llama3', 'llava', 'llm', 'llm-serving', 'moe', 'openai', 'pytorch', 'qwen3', 'transformer', 'vlm']",Python,2024-01-08T04:15:52Z,2025-12-10T05:05:10Z,True,"['docs/references/post_training_integration.md', 'docs/references/post_training_integration.md', 'python/sglang/multimodal_gen/configs/pipeline_configs/flux_finetuned.py', 'python/sglang/srt/constrained/base_grammar_backend.py', 'python/sglang/srt/constrained/llguidance_backend.py']",True,"['.github/workflows/cancel-all-pending-pr-test-runs.yml', '.github/workflows/nightly-test-amd.yml', '.github/workflows/nightly-test-intel.yml', '.github/workflows/nightly-test-npu.yml', '.github/workflows/nightly-test-nvidia.yml']",1661,Apache License 2.0
sentence-transformers,huggingface,https://github.com/huggingface/sentence-transformers,17979,2715,State-of-the-Art Text Embeddings,[],Python,2019-07-24T10:53:51Z,2025-12-10T04:42:17Z,True,"['docs/cross_encoder/pretrained_models.md', 'docs/cross_encoder/training/examples.rst', 'docs/cross_encoder/training_overview.md', 'docs/cross_encoder/training_overview.md', 'docs/img/adaptive_pre-training.png']",True,"['.github/workflows/tests.yml', 'docs/img/backends_benchmark_cpu.png', 'docs/img/backends_benchmark_gpu.png', 'docs/img/ce_backends_benchmark_cpu.png', 'docs/img/ce_backends_benchmark_gpu.png']",1339,Apache License 2.0
trl,huggingface,https://github.com/huggingface/trl,16587,2342,Train transformer language models with reinforcement learning.,[],Python,2020-03-27T10:54:55Z,2025-12-10T03:17:17Z,True,"['.github/issue_template/new-trainer-addition.yml', 'docs/source/bco_trainer.md', 'docs/source/cpo_trainer.md', 'docs/source/distributing_training.md', 'docs/source/dpo_trainer.md']",True,"['.github/workflows/slow-tests.yml', '.github/workflows/tests-experimental.yml', '.github/workflows/tests.yml', '.github/workflows/tests_latest.yml', 'tests/__init__.py']",602,Apache License 2.0
LaTeX-OCR,lukas-blecher,https://github.com/lukas-blecher/LaTeX-OCR,16014,1269,pix2tex: Using a ViT to convert images of equations into LaTeX code.,"['dataset', 'deep-learning', 'im2latex', 'im2markup', 'im2text', 'image-processing', 'image2text', 'latex', 'latex-ocr', 'machine-learning', 'math-ocr', 'ocr', 'python', 'pytorch', 'transformer', 'vision-transformer', 'vit']",Python,2020-12-11T16:35:13Z,2025-12-10T01:40:35Z,True,"['notebooks/latex_ocr_training.ipynb', 'pix2tex/train.py', 'pix2tex/train.py', 'pix2tex/train_resizer.py', 'pix2tex/train_resizer.py']",True,"['notebooks/latex_ocr_test.ipynb', 'pix2tex/dataset/demacro-test.py', 'pix2tex/eval.py', 'pix2tex/model/checkpoints/get_latest_checkpoint.py']",152,MIT License
Swin-Transformer,microsoft,https://github.com/microsoft/Swin-Transformer,15517,2202,"This is an official implementation for ""Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"".","['ade20k', 'image-classification', 'imagenet', 'mask-rcnn', 'mscoco', 'object-detection', 'semantic-segmentation', 'swin-transformer']",Python,2021-03-25T12:42:36Z,2025-12-10T02:28:18Z,True,"['configs/simmim/simmim_finetune__swin_base__img224_window7__800ep.yaml', 'configs/simmim/simmim_finetune__swinv2_base__img224_window14__800ep.yaml', 'configs/simmim/simmim_pretrain__swin_base__img192_window6__800ep.yaml', 'configs/simmim/simmim_pretrain__swin_base__img192_window6__800ep.yaml', 'configs/simmim/simmim_pretrain__swinv2_base__img192_window12__800ep.yaml']",True,['kernels/window_process/unit_test.py'],202,MIT License
detr,facebookresearch,https://github.com/facebookresearch/detr,14945,2639,End-to-End Object Detection with Transformers,[],Python,2020-05-26T23:54:52Z,2025-12-10T04:47:58Z,True,"['d2/train_net.py', 'd2/train_net.py']",True,"['datasets/coco_eval.py', 'datasets/panoptic_eval.py', 'test_all.py']",255,Apache License 2.0
Megatron-LM,NVIDIA,https://github.com/NVIDIA/Megatron-LM,14492,3358,Ongoing research training transformer models at scale,"['large-language-models', 'model-para', 'transformers']",Python,2019-03-21T16:15:52Z,2025-12-10T05:16:53Z,True,"['examples/academic_paper_scripts/detxoify_lm/finetune_gpt.py', 'examples/academic_paper_scripts/detxoify_lm/finetune_gpt_distributed-1.3b.sh', 'examples/bert/train_bert_340m_distributed.sh', 'examples/bert/train_bert_340m_distributed.sh', 'examples/gpt3/train_gpt3_175b_distributed.sh']",True,"['.github/workflows/_build_test_publish_wheel.yml', '.github/workflows/build-test-publish-wheel.yml', '.github/workflows/cicd-approve-test-queue.yml', '.github/workflows/install-test.yml', '.github/workflows/trigger-mbridge-tests.yml']",572,Other
RWKV-LM,BlinkDL,https://github.com/BlinkDL/RWKV-LM,14214,978,"RWKV (pronounced RwaKuv) is an RNN with great LLM performance, which can also be directly trained like a GPT transformer (parallelizable). We are at RWKV-7 ""Goose"". So it's combining the best of RNN and transformer - great performance, linear time, constant space (no kv-cache), fast training, infinite ctx_len, and free sentence embedding.","['attention-mechanism', 'chatgpt', 'deep-learning', 'gpt', 'gpt-2', 'gpt-3', 'language-model', 'linear-attention', 'lstm', 'pytorch', 'rnn', 'rwkv', 'transformer', 'transformers']",Python,2021-08-08T06:05:27Z,2025-12-10T04:01:03Z,True,"['rwkv-v1/src/trainer.py', 'rwkv-v1/train.py', 'rwkv-v1/train.py', 'rwkv-v2-rnn/src/trainer.py', 'rwkv-v2-rnn/train.py']",True,"['rwkv-v7/misc/lambada_test.jsonl', 'rwkv-v7/mmlu_test_dataset/data-00000-of-00001.arrow', 'rwkv-v7/mmlu_test_dataset/dataset_info.json', 'rwkv-v7/mmlu_test_dataset/state.json', 'rwkv-v7/rwkv_mmlu_eval.py']",141,Apache License 2.0
segmentation_models.pytorch,qubvel-org,https://github.com/qubvel-org/segmentation_models.pytorch,11145,1810,Semantic segmentation models with 500+ pretrained convolutional and transformer-based backbones.,"['computer-vision', 'deeplab-v3-plus', 'deeplabv3', 'dpt', 'fpn', 'image-processing', 'image-segmentation', 'imagenet', 'models', 'pretrained-weights', 'pspnet', 'pytorch', 'segformer', 'segmentation', 'segmentation-models', 'semantic-segmentation', 'transformers', 'unet', 'unet-pytorch', 'unetplusplus']",Python,2019-03-01T16:21:21Z,2025-12-09T08:53:35Z,True,"['examples/dpt_inference_pretrained.ipynb', 'examples/segformer_inference_pretrained.ipynb', 'examples/upernet_inference_pretrained.ipynb', 'segmentation_models_pytorch/encoders/_legacy_pretrained_settings.py', 'segmentation_models_pytorch/utils/train.py']",True,"['.github/workflows/tests.yml', 'misc/generate_test_models.py', 'requirements/test.txt', 'tests/__init__.py', 'tests/base/test_freeze_encoder.py']",86,MIT License
lm-evaluation-harness,EleutherAI,https://github.com/EleutherAI/lm-evaluation-harness,10890,2894,A framework for few-shot evaluation of language models.,"['evaluation-framework', 'language-model', 'transformer']",Python,2020-08-28T00:09:15Z,2025-12-10T03:23:58Z,True,"['lm_eval/tasks/blimp/coordinate_structure_constraint_complex_left_branch.yaml', 'lm_eval/tasks/blimp/coordinate_structure_constraint_object_extraction.yaml', 'lm_eval/tasks/e2lmc/mmlu_early_training/readme.md', 'lm_eval/tasks/e2lmc/mmlu_early_training/custom_metrics.py', 'lm_eval/tasks/e2lmc/mmlu_early_training/mmlu_early_training.yaml']",True,"['.github/workflows/unit_tests.yml', 'lm_eval/config/evaluate_config.py', 'lm_eval/tasks/arabic_leaderboard_complete/arabic_leaderboard_alghafa/arabic_leaderboard_alghafa_mcq_exams_test_ar.yaml', 'lm_eval/tasks/arabic_leaderboard_light/arabic_leaderboard_alghafa_light/arabic_leaderboard_alghafa_mcq_exams_test_ar_light.yaml', 'lm_eval/tasks/arabicmmlu/arabicmmlu_driving_test.yaml']",691,MIT License
text-generation-inference,huggingface,https://github.com/huggingface/text-generation-inference,10693,1244,Large Language Model Text Generation Inference,"['bloom', 'deep-learning', 'falcon', 'gpt', 'inference', 'nlp', 'pytorch', 'starcoder', 'transformer']",Python,2022-10-08T10:26:28Z,2025-12-09T08:43:07Z,True,"['docs/source/basic_tutorials/train_medusa.md', 'docs/source/basic_tutorials/train_medusa.md', 'integration-tests/models/__snapshots__/test_json_schema_constrain/test_json_schema_basic.json', 'integration-tests/models/__snapshots__/test_json_schema_constrain/test_json_schema_complex.json', 'integration-tests/models/__snapshots__/test_json_schema_constrain/test_json_schema_stream.json']",True,"['.github/workflows/client-tests.yaml', '.github/workflows/integration_tests.yaml', '.github/workflows/load_test.yaml', '.github/workflows/nix_tests.yaml', '.github/workflows/tests.yaml']",317,Apache License 2.0
xformers,facebookresearch,https://github.com/facebookresearch/xformers,10167,744,"Hackable and optimized Transformers building blocks, supporting a composable construction.",[],Python,2021-10-13T18:08:50Z,2025-12-09T18:03:33Z,True,['xformers/ops/fmha/merge_training.py'],True,"['.github/gpu_benchmark_diff.py', '.github/run_benchmark_wrapper.py', '.github/workflows/gpu_test_gh.yml', 'requirements-test.txt', 'stubs/torch_stub_tests.py']",366,Other
petals,bigscience-workshop,https://github.com/bigscience-workshop/petals,9851,586,"ğŸŒ¸ Run LLMs at home, BitTorrent-style. Fine-tuning and inference up to 10x faster than offloading","['bloom', 'chatbot', 'deep-learning', 'distributed-systems', 'falcon', 'gpt', 'guanaco', 'language-models', 'large-language-models', 'llama', 'machine-learning', 'mixtral', 'neural-networks', 'nlp', 'pipeline-parallelism', 'pretrained-models', 'pytorch', 'tensor-parallelism', 'transformer', 'volunteer-computing']",Python,2022-06-12T00:10:27Z,2025-12-09T08:50:16Z,True,"['benchmarks/benchmark_training.py', 'src/petals/client/from_pretrained.py', 'src/petals/server/from_pretrained.py']",True,"['.github/workflows/run-tests.yaml', 'benchmarks/benchmark_forward.py', 'benchmarks/benchmark_inference.py', 'benchmarks/benchmark_training.py', 'tests/bootstrap.id']",111,MIT License
mmsegmentation,open-mmlab,https://github.com/open-mmlab/mmsegmentation,9470,2802,OpenMMLab Semantic Segmentation Toolbox and Benchmark.,"['deeplabv3', 'image-segmentation', 'medical-image-segmentation', 'pspnet', 'pytorch', 'realtime-segmentation', 'retinal-vessel-segmentation', 'semantic-segmentation', 'swin-transformer', 'transformer', 'vessel-segmentation']",Python,2020-06-14T04:32:33Z,2025-12-10T02:02:38Z,True,"['.dev_scripts/batch_train_list.txt', '.dev_scripts/batch_train_list.txt', '.dev_scripts/benchmark_train.sh', '.dev_scripts/benchmark_train_models.txt', '.dev_scripts/benchmark_train_models.txt']",True,"['.circleci/test.yml', '.dev_scripts/batch_test_list.py', '.dev_scripts/benchmark_evaluation.sh', '.dev_scripts/benchmark_full_models.txt', '.dev_scripts/benchmark_inference.py']",866,Apache License 2.0
manga-image-translator,zyddnys,https://github.com/zyddnys/manga-image-translator,9000,883,Translate manga/image ä¸€é”®ç¿»è¯‘å„ç±»å›¾ç‰‡å†…æ–‡å­— https://cotrans.touhou.ai/ (no longer working),"['anime', 'auto-translation', 'chinese-translation', 'deep-learning', 'image-processing', 'inpainting', 'japanese-translations', 'machine-translation', 'manga', 'neural-network', 'ocr', 'pytorch-implementation', 'text-detection', 'text-detection-recognition', 'transformer']",Python,2021-02-18T03:03:23Z,2025-12-10T03:29:23Z,True,"['training/all-fonts.txt', 'training/inpainting/readme.md', 'training/ocr/readme.md', 'training/ocr/custom_ctc.cc', 'training/ocr/custom_ctc.py']",True,"['pytest.ini', 'test/readme.md', 'test/api_test.html', 'test/conftest.py', 'test/test_render.py']",235,GNU General Public License v3.0
LMFlow,OptimalScale,https://github.com/OptimalScale/LMFlow,8489,834,An Extensible Toolkit for Finetuning and Inference of Large Foundation Models. Large Models for All.,"['chatgpt', 'deep-learning', 'instruction-following', 'language-model', 'pretrained-models', 'pytorch', 'transformer']",Python,2023-03-27T13:56:29Z,2025-12-10T04:51:11Z,True,"['contrib/long-context/hf_sft_full_finetune.sh', 'contrib/text2image/diffuser_finetuner.py', 'contrib/text2image/finetune_t2i.py', 'contrib/text2image/finetune_t2i.sh', 'contrib/tool-finetune/readme.md']",True,"['experimental/lisa-diffusion/instruct_pix2pix/test_instruct_pix2pix.py', 'scripts/run_unittest.sh', 'src/lmflow/utils/test_utils.py', 'tests/__init__.py', 'tests/conftest.py']",84,Apache License 2.0
trax,google,https://github.com/google/trax,8294,827,Trax â€” Deep Learning with Clear Code and Speed,"['deep-learning', 'deep-reinforcement-learning', 'jax', 'machine-learning', 'numpy', 'reinforcement-learning', 'transformer']",Python,2019-10-05T15:09:14Z,2025-12-08T16:44:36Z,True,"['trax/data/testdata/c4/en/2.3.0/c4-train.tfrecord-00000-of-00001', 'trax/data/testdata/para_crawl/ende/1.2.0/para_crawl-train.tfrecord-00000-of-00001', 'trax/data/testdata/squad/v1.1/3.0.0/squad-train.tfrecord-00000-of-00001', 'trax/models/reformer/testdata/translate_ende_wmt32k-train-00000-of-00001', 'trax/models/research/testdata/translate_ende_wmt32k-train-00000-of-00001']",True,"['oss_scripts/oss_tests.sh', 'trax/data/inputs_test.py', 'trax/data/testdata/bert_uncased_vocab.txt', 'trax/data/testdata/c4/en/2.3.0/c4-train.tfrecord-00000-of-00001', 'trax/data/testdata/c4/en/2.3.0/c4-validation.tfrecord-00000-of-00001']",125,Apache License 2.0
jukebox,openai,https://github.com/openai/jukebox,8034,1456,"Code for the paper ""Jukebox: A Generative Model for Music""","['audio', 'generative-model', 'music', 'paper', 'pytorch', 'transformer', 'vq-vae']",Python,2020-04-29T17:16:12Z,2025-12-09T13:37:44Z,True,"['jukebox/train.py', 'jukebox/train.py', 'tensorboardx/examples/chainer/extension_logger/train_dcgan.py', 'tensorboardx/examples/chainer/extension_logger/train_dcgan.py', 'tensorboardx/examples/chainer/plain_logger/train_vae.py']",True,"['apex/tests/l0/run_amp/__init__.py', 'apex/tests/l0/run_amp/test_add_param_group.py', 'apex/tests/l0/run_amp/test_basic_casts.py', 'apex/tests/l0/run_amp/test_cache.py', 'apex/tests/l0/run_amp/test_multi_tensor_axpby.py']",207,Other
GPT2-Chinese,Morizeyao,https://github.com/Morizeyao/GPT2-Chinese,7601,1699,"Chinese version of GPT2 training code, using BERT tokenizer.","['chinese', 'gpt-2', 'nlp', 'text-generation', 'transformer']",Python,2019-05-31T02:07:50Z,2025-12-09T14:23:50Z,True,"['scripts/train.sh', 'train.py', 'train.py', 'train.sh']",True,['config/model_config_test.json'],109,MIT License
gpt-neox,EleutherAI,https://github.com/EleutherAI/gpt-neox,7348,1092,"An implementation of model parallel autoregressive transformers on GPUs, based on the Megatron and DeepSpeed libraries","['deepspeed-library', 'gpt-3', 'language-model', 'transformers']",Python,2020-12-22T14:37:54Z,2025-12-10T02:49:53Z,True,"['configs/finetuning_configs/6-9b.yml', 'configs/llama/train_config.yml', 'configs/llama/train_config.yml', 'megatron/tokenizer/train_tokenizer.py', 'megatron/tokenizer/train_tokenizer.py']",True,"['eval.py', 'tests/readme.md', 'tests/__init__.py', 'tests/common.py', 'tests/config/test_setup.yml']",87,Apache License 2.0
donut,clovaai,https://github.com/clovaai/donut,6701,549,"Official Implementation of OCR-free Document Understanding Transformer (Donut) and Synthetic Document Generator (SynthDoG), ECCV 2022","['computer-vision', 'document-ai', 'eccv-2022', 'multimodal-pre-trained-model', 'nlp', 'ocr']",Python,2022-07-20T01:21:19Z,2025-12-10T02:58:10Z,True,"['config/train_cord.yaml', 'config/train_cord.yaml', 'config/train_docvqa.yaml', 'config/train_docvqa.yaml', 'config/train_rvlcdip.yaml']",True,"['misc/sample_image_cord_test_receipt_00004.png', 'test.py']",210,MIT License
BERT-pytorch,codertimo,https://github.com/codertimo/BERT-pytorch,6505,1329,Google AI 2018 BERT pytorch implementation,"['bert', 'language-model', 'nlp', 'pytorch', 'transformer']",Python,2018-10-15T12:58:15Z,2025-12-10T02:25:35Z,True,"['bert/pretrain/__init__.py', 'bert/pretrain/dataset.py', 'bert/pretrain/feature.py', 'bert/pretrain/utils.py', 'scripts/create_pretraining_dataset.py']",True,"['tests/__init__.py', 'tests/test_model.py', 'tests/test_sample.py']",68,Apache License 2.0
ProPainter,sczhou,https://github.com/sczhou/ProPainter,6401,754,[ICCV 2023] ProPainter: Improving Propagation and Transformer for Video Inpainting,"['object-removal', 'video-completion', 'video-inpainting', 'video-outpainting', 'watermark-removal']",Python,2023-09-01T13:11:57Z,2025-12-10T04:30:20Z,True,"['configs/train_flowcomp.json', 'configs/train_flowcomp.json', 'configs/train_propainter.json', 'configs/train_propainter.json', 'core/trainer.py']",True,"['datasets/davis/test.json', 'datasets/youtube-vos/test.json', 'scripts/evaluate_flow_completion.py', 'scripts/evaluate_propainter.py', 'web-demos/hugging_face/test_sample/test-sample0.mp4']",73,Other
x-transformers,lucidrains,https://github.com/lucidrains/x-transformers,5710,497,A concise but complete full-attention transformer with a set of promising experimental features from various papers,"['artificial-intelligence', 'attention-mechanism', 'deep-learning', 'transformers']",Python,2020-10-24T22:13:25Z,2025-12-08T08:19:07Z,True,"['train_belief_state.py', 'train_belief_state.py', 'train_copy.py', 'train_copy.py', 'train_entropy_tokenizer.py']",True,"['.github/workflows/python-test.yaml', 'tests/test_x_transformers.py']",71,MIT License
Chinese-Text-Classification-Pytorch,649453932,https://github.com/649453932/Chinese-Text-Classification-Pytorch,5688,1262,ä¸­æ–‡æ–‡æœ¬åˆ†ç±»ï¼ŒTextCNNï¼ŒTextRNNï¼ŒFastTextï¼ŒTextRCNNï¼ŒBiLSTM_Attentionï¼ŒDPCNNï¼ŒTransformerï¼ŒåŸºäºpytorchï¼Œå¼€ç®±å³ç”¨ã€‚,[],Python,2019-07-11T01:38:08Z,2025-12-09T13:47:39Z,True,"['thucnews/data/train.txt', 'train_eval.py', 'train_eval.py']",True,"['thucnews/data/test.txt', 'train_eval.py']",83,MIT License
wenet,wenet-e2e,https://github.com/wenet-e2e/wenet,4942,1172,Production First and Production Ready End-to-End Speech Recognition Toolkit,"['asr', 'automatic-speech-recognition', 'conformer', 'e2e-models', 'production-ready', 'pytorch', 'speech-recognition', 'transformer', 'whisper']",Python,2020-11-17T03:57:23Z,2025-12-08T13:47:48Z,True,"['docs/pretrained_models.md', 'docs/train.rst', 'examples/aishell/nst/conf/train_conformer.yaml', 'examples/aishell/nst/conf/train_conformer.yaml', 'examples/aishell/paraformer/conf/train_paraformer.yaml']",True,"['.github/workflows/unit_test.yml', 'examples/csj/s0/list_files/test.set.1.list', 'examples/csj/s0/list_files/test.set.123.list', 'examples/csj/s0/list_files/test.set.2.list', 'examples/csj/s0/list_files/test.set.3.list']",23,Apache License 2.0
OpenPrompt,thunlp,https://github.com/thunlp/OpenPrompt,4788,484,An Open-Source Framework for Prompt-Learning.,"['ai', 'deep-learning', 'natural-language-processing', 'natural-language-understanding', 'nlp', 'nlp-library', 'nlp-machine-learning', 'pre-trained-language-models', 'pre-trained-model', 'prompt', 'prompt-based-tuning', 'prompt-learning', 'prompt-toolkit', 'prompts', 'pytorch', 'transformer']",Python,2021-09-30T09:38:45Z,2025-12-09T21:52:32Z,True,"['docs/source/modules/trainer.rst', 'openprompt/lm_bff_trainer.py', 'openprompt/protoverb_trainer.py', 'openprompt/trainer.py', 'tutorial/7_ernie_paddlepaddle/train.tsv']",True,"['docs/source/notes/test.md', 'test/test_data_processor/test_condition_generation_dataset.py', 'test/test_data_processor/test_lama_dataset.py', 'test/test_data_processor/test_nli_dataset.py', 'test/test_data_processor/test_relation_classification_dataset.py']",100,Apache License 2.0
Sana,NVlabs,https://github.com/NVlabs/Sana,4781,313,SANA: Efficient High-Resolution Image Synthesis with Linear Diffusion Transformer,"['diffusion', 'dit', 'pytorch', 'sana', 'text-to-image-generation', 'transformers']",Python,2024-10-11T20:19:45Z,2025-12-10T04:06:25Z,True,"['asset/samples/longsana_train.txt', 'diffusion/longsana/pipeline/sana_switch_training_pipeline.py', 'diffusion/longsana/pipeline/sana_switch_training_pipeline.py', 'diffusion/longsana/pipeline/sana_training_pipeline.py', 'diffusion/longsana/pipeline/sana_training_pipeline.py']",True,"['scripts/inference_geneval.py', 'scripts/inference_sana_sprint_geneval.py', 'tests/bash/entry.sh', 'tests/bash/inference/test_inference.sh', 'tests/bash/setup_test_data.sh']",92,Apache License 2.0
transformerlab-app,transformerlab,https://github.com/transformerlab/transformerlab-app,4581,465,"Open Source Application for Advanced LLM + Diffusion Engineering: interact, train, fine-tune, and evaluate large language models on your own computer.","['diffusion', 'diffusion-models', 'electron', 'llama', 'llms', 'lora', 'mlx', 'rlhf', 'stability-diffusion', 'transformers']",Python,2023-12-24T22:09:14Z,2025-12-09T23:54:28Z,True,"['api/scripts/xml-rpc-client-example/train_example.py', 'api/scripts/xml-rpc-client-example/train_example.py', 'api/scripts/xml-rpc-client-example/training_client_example.py', 'api/scripts/xml-rpc-client-example/training_client_example.py', 'api/test/api/test_train.py']",True,"['.github/workflows/pytest-sdk.yml', '.github/workflows/pytest-server-test-macos.yml', '.github/workflows/pytest-server-test.yml', '.github/workflows/pytest.yml', '.github/workflows/test.yml']",68,GNU Affero General Public License v3.0
RT-DETR,lyuwenyu,https://github.com/lyuwenyu/RT-DETR,4557,534,"[CVPR 2024] Official RT-DETR (RTDETR paddle pytorch), Real-Time DEtection TRansformer, DETRs Beat YOLOs on Real-time Object Detection. ğŸ”¥ ğŸ”¥ ğŸ”¥ ","['rtdetr', 'rtdetrv2']",Python,2023-05-10T06:35:56Z,2025-12-10T03:19:05Z,True,"['rtdetr_paddle/ppdet/engine/trainer.py', 'rtdetr_paddle/tools/train.py', 'rtdetr_paddle/tools/train.py', 'rtdetr_pytorch/tools/train.py', 'rtdetr_pytorch/tools/train.py']",True,"['rtdetr_paddle/ppdet/modeling/transformers/ext_op/test_ms_deformable_attn_op.py', 'rtdetr_paddle/tools/eval.py', 'rtdetr_pytorch/src/data/coco/coco_eval.py', 'rtdetr_pytorch/src/nn/backbone/test_resnet.py', 'rtdetrv2_pytorch/src/data/dataset/coco_eval.py']",402,Apache License 2.0
transformer,Kyubyong,https://github.com/Kyubyong/transformer,4450,1312,A TensorFlow Implementation of the Transformer: Attention Is All You Need,"['attention-is-all-you-need', 'attention-mechanism', 'implementation', 'transformer', 'translation']",Python,2017-06-17T11:08:40Z,2025-12-09T06:07:58Z,True,"['tf1.2_legacy/train.py', 'tf1.2_legacy/train.py', 'train.py', 'train.py']",True,"['test.py', 'test/1/iwslt2016_e19l2.64-29146b23.88', 'tf1.2_legacy/eval.py']",136,Apache License 2.0
Efficient-AI-Backbones,huawei-noah,https://github.com/huawei-noah/Efficient-AI-Backbones,4353,735,"Efficient AI Backbones including GhostNet, TNT and MLP, developed by Huawei Noah's Ark Lab.","['convolutional-neural-networks', 'efficient-inference', 'ghostnet', 'imagenet', 'model-compression', 'pretrained-models', 'pytorch', 'tensorflow', 'transformer', 'vision-transformer']",Python,2019-11-16T14:21:35Z,2025-12-09T15:26:57Z,True,"['augvit_pytorch/train.py', 'augvit_pytorch/train.py', 'cmt_pytorch/train.py', 'cmt_pytorch/train.py', 'ghostnetv2_pytorch/train.py']",True,"['snnmlp_pytorch/train_scripts/test.sh', 'tinynet_pytorch/eval.py']",94,Unknown
transformer,hyunwoongko,https://github.com/hyunwoongko/transformer,4308,612,"Transformer: PyTorch Implementation of ""Attention Is All You Need""","['attention', 'dataset', 'pytorch', 'transformer']",Python,2019-10-15T10:36:00Z,2025-12-09T16:18:58Z,True,"['saved/transformer-base/train.txt', 'saved/transformer-base/train_result.jpg', 'saved/transformer-base/train_result.jpg', 'train.py', 'train.py']",True,['saved/transformer-base/test.txt'],18,Unknown
simpletransformers,ThilinaRajapakse,https://github.com/ThilinaRajapakse/simpletransformers,4231,726,"Transformers for Information Retrieval, Text Classification, NER, QA, Language Modelling, Language Generation, T5, Multi-Modal, and Conversational AI","['conversational-ai', 'information-retrival', 'named-entity-recognition', 'question-answering', 'text-classification', 'transformers']",Python,2019-10-04T06:11:14Z,2025-12-06T23:29:01Z,True,"['examples/hyperparameter tuning/extended-tuning/train_default.py', 'examples/hyperparameter tuning/extended-tuning/train_default.py', 'examples/hyperparameter tuning/extended-tuning/train_layerwise.py', 'examples/hyperparameter tuning/extended-tuning/train_layerwise.py', 'examples/hyperparameter tuning/extended-tuning/train_vanilla.py']",True,"['examples/t5/mixed_tasks/test.py', 'examples/t5/mt5/test.py', 'examples/t5/mt5/test_multi_lang.py', 'examples/t5/mt5_translation/test.py', 'examples/t5/training_on_a_new_task/test.py']",54,Apache License 2.0
transformer-xl,kimiyoung,https://github.com/kimiyoung/transformer-xl,3680,765,,[],Python,2019-01-08T12:20:24Z,2025-11-27T05:58:07Z,True,"['pytorch/train.py', 'pytorch/train.py', 'tf/train.py', 'tf/train.py', 'tf/train_gpu.py']",True,['pytorch/eval.py'],97,Apache License 2.0
towhee,towhee-io,https://github.com/towhee-io/towhee,3439,262,Towhee is a framework that is dedicated to making neural data processing pipelines simple and fast.,"['computer-vision', 'convolutional-networks', 'embedding-vectors', 'embeddings', 'feature-extraction', 'feature-vector', 'image-processing', 'image-retrieval', 'llm', 'machine-learning', 'milvus', 'pipeline', 'towhee', 'transformer', 'unstructured-data', 'video-processing', 'vision-transformer', 'vit']",Python,2021-07-13T08:28:50Z,2025-12-09T17:11:21Z,True,"['tests/unittests/data/dataset/kaggle_dataset_small/train/000bec180eb18c7604dcecc8fe0dba07.jpg', 'tests/unittests/data/dataset/kaggle_dataset_small/train/001513dfcb2ffafc82cccf4d8bbaba97.jpg', 'tests/unittests/data/dataset/kaggle_dataset_small/train/001cdf01b096e06d78e9e5112d419397.jpg', 'tests/unittests/data/dataset/kaggle_dataset_small/train/00214f311d5d2247d5dfe4fe24b2303d.jpg', 'tests/unittests/data/dataset/kaggle_dataset_small/train/0021f9ceb3235effd7fcde7f7538ed62.jpg']",True,"['.github/workflows/pr_test.yml', 'test_requirements.txt', 'tests/__init__.py', 'tests/common/common_func.py', 'tests/testcases/audios/towhee_test_audio_0.wav']",0,Apache License 2.0
HRNet-Semantic-Segmentation,HRNet,https://github.com/HRNet/HRNet-Semantic-Segmentation,3305,697,The OCR approach is rephrased as Segmentation Transformer: https://arxiv.org/abs/1909.11065. This is an official implementation of semantic segmentation for HRNet. https://arxiv.org/abs/1908.07919,"['cityscapes', 'high-resolution', 'high-resolution-net', 'hrnets', 'lip', 'pascal-context', 'segmentation', 'segmentation-transformer', 'semantic-segmentation', 'transformer']",Python,2019-04-09T13:24:09Z,2025-12-08T14:11:52Z,True,"['data/list/cityscapes/train.lst', 'data/list/cityscapes/trainval.lst', 'data/list/lip/trainlist.txt', 'experiments/cityscapes/seg_hrnet_w48_train_512x1024_sgd_lr1e-2_wd5e-4_bs_12_epoch484.yaml', 'experiments/cityscapes/seg_hrnet_w48_train_512x1024_sgd_lr1e-2_wd5e-4_bs_12_epoch484.yaml']",True,"['data/list/cityscapes/test.lst', 'data/list/lip/testvallist.txt', 'tools/test.py']",163,Other
SwanLab,SwanHubX,https://github.com/SwanHubX/SwanLab,3230,176,"âš¡ï¸SwanLab - an open-source, modern-design AI training tracking and visualization tool. Supports Cloud / Self-hosted use. Integrated with PyTorch / Transformers / LLaMA Factory / veRL/ Swift / Ultralytics / MMEngine / Keras etc.","['data-science', 'deep-learning', 'logging', 'machine-learning', 'mlops', 'model-versioning', 'python', 'pytorch', 'tensorboard', 'tensorflow', 'tracking', 'transformers', 'visualization']",Python,2023-11-24T08:54:45Z,2025-12-10T01:38:33Z,True,"['test/integration/accelerate/accelerate_train.py', 'test/integration/accelerate/accelerate_train.py', 'test/integration/fastai/fastai_train.py', 'test/integration/fastai/fastai_train.py', 'test/integration/keras/keras_train.py']",True,"['.github/workflows/test-core.yml', '.github/workflows/test-when-pr.yml', 'core/internal/api/parse_test.go', 'test/config/config.json', 'test/config/load.yaml']",52,Apache License 2.0
SegFormer,NVlabs,https://github.com/NVlabs/SegFormer,3228,412,Official PyTorch implementation of SegFormer,"['ade20k', 'cityscapes', 'semantic-segmentation', 'transformer']",Python,2021-06-11T17:22:07Z,2025-12-10T02:08:37Z,True,"['docs/train.md', 'docs/tutorials/training_tricks.md', 'docs/tutorials/training_tricks.md', 'mmseg/apis/train.py', 'mmseg/apis/train.py']",True,"['mmseg/apis/test.py', 'mmseg/datasets/pipelines/test_time_aug.py', 'pytest.ini', 'requirements/tests.txt', 'tests/test_config.py']",109,Other
Mask2Former,facebookresearch,https://github.com/facebookresearch/Mask2Former,3133,483,"Code release for ""Masked-attention Mask Transformer for Universal Image Segmentation""",[],Python,2021-11-24T16:00:44Z,2025-12-10T02:20:30Z,True,"['tools/convert-pretrained-swin-model-to-d2.py', 'train_net.py', 'train_net.py', 'train_net_video.py', 'train_net_video.py']",True,"['mask2former/modeling/pixel_decoder/ops/test.py', 'mask2former/test_time_augmentation.py', 'mask2former_video/data_video/datasets/ytvis_api/ytvoseval.py', 'mask2former_video/data_video/ytvis_eval.py', 'tools/evaluate_coco_boundary_ap.py']",164,MIT License
yolov7_d2,lucasjinreal,https://github.com/lucasjinreal/yolov7_d2,3124,476,"ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ (Earlier YOLOv7 not official one) YOLO with Transformers and Instance Segmentation, with TensorRT acceleration! ğŸ”¥ğŸ”¥ğŸ”¥","['detection', 'detextron2', 'detr', 'face', 'instance-segmentation', 'object-detection', 'onnx', 'tensorrt', 'transformers', 'yolo', 'yolov6', 'yolov7', 'yolox']",Python,2021-06-23T11:35:35Z,2025-12-10T00:54:53Z,True,"['configs/common/train.py', 'configs/common/train.py', 'tools/lazyconfig_train_net.py', 'tools/lazyconfig_train_net.py', 'tools/train_detr.py']",True,"['deploy/quant_fx/fx_ptq_test.py', 'deploy/quant_fx/qt_mq_test.py', 'deploy/quant_fx/qt_q_test.py', 'deploy/quant_fx/quant_ptq_test.py', 'deploy/quant_fx/test.py']",69,GNU General Public License v3.0
torchscale,microsoft,https://github.com/microsoft/torchscale,3124,222,Foundation Architecture for (M)LLMs,"['computer-vision', 'machine-learning', 'multimodal', 'natural-language-processing', 'pretrained-language-model', 'speech-processing', 'transformer', 'translation']",Python,2022-11-17T08:55:59Z,2025-12-09T09:57:27Z,True,"['examples/fairseq/tasks/pretraining.py', 'examples/fairseq/train.py', 'examples/fairseq/train.py', 'examples/longvit/engine_for_finetuning.py', 'examples/longvit/get_started/get_started_for_tcga_pretraining.md']",True,"['.github/workflows/test.yml', 'tests/__init__.py', 'tests/test_decoder.py', 'tests/test_encoder.py', 'tests/test_encoder_decoder.py']",36,MIT License
TransUNet,Beckschen,https://github.com/Beckschen/TransUNet,3020,567,"This repository includes the official project of TransUNet, presented in our paper: TransUNet: Transformers Make Strong Encoders for Medical Image Segmentation.",[],Python,2021-02-08T06:12:54Z,2025-12-09T15:00:44Z,True,"['lists/lists_synapse/train.txt', 'train.py', 'train.py', 'trainer.py']",True,"['lists/lists_synapse/test_vol.txt', 'test.py']",137,Apache License 2.0
TransformerEngine,NVIDIA,https://github.com/NVIDIA/TransformerEngine,2992,572,"A library for accelerating Transformer models on NVIDIA GPUs, including using 8-bit and 4-bit floating point (FP8 and FP4) precision on Hopper, Ada and Blackwell GPUs, to provide better performance with lower memory utilization in both training and inference.","['cuda', 'deep-learning', 'fp4', 'fp8', 'gpu', 'jax', 'machine-learning', 'python', 'pytorch']",Python,2022-09-20T15:20:26Z,2025-12-10T03:25:49Z,True,['docs/examples/comparison-fp8-bf16-training-nvidia-dgx-cloud-benchmarking-performance-explorer.jpg'],True,"['benchmarks/attention/benchmark_attention.py', 'benchmarks/benchmark_rht_cast.py', 'benchmarks/linear/benchmark_grouped_linear.py', 'examples/jax/collective_gemm/conftest.py', 'examples/jax/collective_gemm/run_test_cgemm.sh']",370,Apache License 2.0
TransformerLens,TransformerLensOrg,https://github.com/TransformerLensOrg/TransformerLens,2853,479,A library for mechanistic interpretability of GPT-style language models,[],Python,2022-08-26T20:20:38Z,2025-12-09T18:26:32Z,True,"['tests/integration/test_loading_from_pretrained.py', 'tests/unit/pretrained_weight_conversions/test_neo.py', 'tests/unit/test_loading_from_pretrained_utilities.py', 'transformer_lens/loading_from_pretrained.py', 'transformer_lens/pretrained/__init__.py']",True,"['demos/conftest.py', 'tests/acceptance/test_activation_cache.py', 'tests/acceptance/test_evals.py', 'tests/acceptance/test_hook_tokens.py', 'tests/acceptance/test_hooked_encoder.py']",166,MIT License
table-transformer,microsoft,https://github.com/microsoft/table-transformer,2798,304,Table Transformer (TATR) is a deep learning model for extracting tables from unstructured documents (PDFs and images). This is also the official repository for the PubTables-1M dataset and GriTS evaluation metric.,"['table-detection', 'table-extraction', 'table-functional-analysis', 'table-structure-recognition']",Python,2021-05-17T19:01:34Z,2025-12-10T02:18:20Z,True,"['detr/d2/train_net.py', 'detr/d2/train_net.py']",True,"['detr/datasets/coco_eval.py', 'detr/datasets/panoptic_eval.py', 'detr/test_all.py', 'src/eval.py']",106,MIT License
decision-transformer,kzl,https://github.com/kzl/decision-transformer,2718,504,Official codebase for Decision Transformer: Reinforcement Learning via Sequence Modeling.,[],Python,2021-06-02T09:35:37Z,2025-12-09T16:52:43Z,True,"['atari/mingpt/trainer_atari.py', 'gym/decision_transformer/training/act_trainer.py', 'gym/decision_transformer/training/seq_trainer.py', 'gym/decision_transformer/training/trainer.py']",True,['gym/decision_transformer/evaluation/evaluate_episodes.py'],37,MIT License
ao,pytorch,https://github.com/pytorch/ao,2559,383,PyTorch native quantization and sparsity for training and inference,"['brrr', 'cuda', 'dtypes', 'float8', 'inference', 'llama', 'mx', 'offloading', 'optimizer', 'pytorch', 'quantization', 'sparsity', 'training', 'transformer']",Python,2023-11-03T21:27:36Z,2025-12-10T04:37:27Z,True,"['benchmarks/benchmark_semi_sparse_training.py', 'benchmarks/float8/profile_lowp_training.py', 'benchmarks/float8/training/readme.md', 'benchmarks/float8/training/bench.sh', 'benchmarks/float8/training/llama3.sh']",True,"['.github/scripts/ci_test_xpu.sh', '.github/workflows/1xh100_tests.yml', '.github/workflows/1xl4_tests.yml', '.github/workflows/4xh100_tests.yml', '.github/workflows/dashboard_perf_test.yml']",557,Other
mPLUG-Owl,X-PLUG,https://github.com/X-PLUG/mPLUG-Owl,2536,191,mPLUG-Owl: The Powerful Multi-modal Large Language Model  Family,"['alpaca', 'chatbot', 'chatgpt', 'damo', 'dialogue', 'gpt', 'gpt4', 'gpt4-api', 'huggingface', 'instruction-tuning', 'large-language-models', 'llama', 'mplug', 'mplug-owl', 'multimodal', 'pretraining', 'pytorch', 'transformer', 'video', 'visual-recognition']",Python,2023-04-25T02:31:04Z,2025-12-10T03:32:31Z,True,"['mplug-owl/pipeline/train.py', 'mplug-owl/pipeline/train.py', 'mplug-owl/scripts/train_it.sh', 'mplug-owl/scripts/train_it.sh', 'mplug-owl/scripts/train_it_wo_lora.sh']",True,"['mplug-owl2/mplug_owl2/evaluate/evaluate_caption.py', 'mplug-owl2/mplug_owl2/evaluate/evaluate_mmbench.py', 'mplug-owl2/mplug_owl2/evaluate/evaluate_mme.py', 'mplug-owl2/mplug_owl2/evaluate/evaluate_mmmu.py', 'mplug-owl2/mplug_owl2/evaluate/evaluate_vqa.py']",100,MIT License
EasyLM,young-geng,https://github.com/young-geng/EasyLM,2502,258,"Large language models (LLMs) made easy, EasyLM is a one stop solution for pre-training, finetuning, evaluating and serving LLMs in JAX/Flax.","['chatbot', 'deep-learning', 'flax', 'jax', 'language-model', 'large-language-models', 'llama', 'natural-language-processing', 'transformer']",Python,2022-11-22T12:55:20Z,2025-11-30T01:17:20Z,True,"['easylm/models/llama/llama_train.py', 'easylm/models/llama/llama_train.py', 'examples/pretrain_llama_7b.sh', 'examples/pretrain_llama_7b.sh']",True,['easylm/scripts/benchmark_attention.py'],31,Apache License 2.0
DialoGPT,microsoft,https://github.com/microsoft/DialoGPT,2411,350,Large-scale pretraining for dialogue,"['data-processing', 'dialogpt', 'dialogue', 'gpt-2', 'machine-learning', 'pytorch', 'text-data', 'text-generation', 'transformer']",Python,2019-08-29T21:07:46Z,2025-11-25T19:28:18Z,True,"['lsp_train.py', 'lsp_train.py', 'data/train_raw.tsv', 'data/train_raw.tsv', 'gpt2_training/distributed.py']",True,"['dstc/batch_eval.py', 'dstc/data/processed/test_real.keys.txt', 'pycocoevalcap/eval.py', 'reddit_extractor/data/keys-test.gz', 'reddit_extractor/data/test-multi-refs-ids.txt']",64,MIT License
llm-compressor,vllm-project,https://github.com/vllm-project/llm-compressor,2367,312,Transformers-compatible library for applying various compression algorithms to LLMs for optimized deployment with vLLM,"['compression', 'quantization', 'sparsity']",Python,2024-06-20T20:13:34Z,2025-12-10T04:48:23Z,True,"['examples/finetuning/configure_fsdp.md', 'examples/finetuning/example_alternating_recipe.yaml', 'examples/finetuning/example_fsdp_config.yaml', 'examples/finetuning/example_single_gpu_config.yaml']",True,"['.github/workflows/test-check-transformers.yaml', '.github/workflows/test-check.yaml', 'tests/__init__.py', 'tests/e2e/__init__.py', 'tests/e2e/e2e_utils.py']",120,Apache License 2.0
Restormer,swz30,https://github.com/swz30/Restormer,2320,290,"[CVPR 2022--Oral] Restormer: Efficient Transformer for High-Resolution Image Restoration. SOTA  for motion deblurring, image deraining, denoising (Gaussian/real data), and defocus deblurring. ","['cvpr2022', 'defocus-deblurring', 'efficient-transformers', 'high-resolution', 'image-deblurring', 'image-deraining', 'image-restoration', 'low-level-vision', 'motion-deblurring', 'pytorch', 'transformer']",Python,2021-10-19T06:09:34Z,2025-12-09T07:43:29Z,True,"['defocus_deblurring/pretrained_models/readme.md', 'denoising/pretrained_models/readme.md', 'deraining/pretrained_models/readme.md', 'motion_deblurring/pretrained_models/readme.md', 'basicsr/data/meta_info/meta_info_vimeo90k_train_gt.txt']",True,"['defocus_deblurring/test_dual_pixel_defocus_deblur.py', 'defocus_deblurring/test_single_image_defocus_deblur.py', 'denoising/evaluate_gaussian_color_denoising.py', 'denoising/evaluate_gaussian_gray_denoising.py', 'denoising/evaluate_sidd.m']",55,MIT License
flow-forecast,AIStream-Peelout,https://github.com/AIStream-Peelout/flow-forecast,2260,303,"Deep learning PyTorch library for time series forecasting, classification, and anomaly detection (originally for flood forecasting).","['anomaly-detection', 'deep-learning', 'deep-neural-networks', 'forecasting', 'hacktoberfest', 'lstm', 'pytorch', 'state-of-the-art-models', 'time-series', 'time-series-analysis', 'time-series-forecasting', 'time-series-regression', 'transfer-learning', 'transformer']",Python,2019-08-15T17:02:09Z,2025-12-05T04:31:18Z,True,"['docs/source/long_train.rst', 'docs/source/pytorch_training.rst', 'docs/source/train_da.rst', 'docs/source/train_da.rst', 'docs/source/trainer.rst']",True,"['tests/24_may_202202_25pm_1.json', 'tests/__init__.py', 'tests/auto_encoder.json', 'tests/classification_test.json', 'tests/config.json']",109,GNU General Public License v3.0
Swin-Unet,HuCaoFighting,https://github.com/HuCaoFighting/Swin-Unet,2251,356,"[ECCVW 2022] The codes for the work ""Swin-Unet: Unet-like Pure Transformer for Medical Image Segmentation""",[],Python,2021-05-03T07:37:40Z,2025-12-10T02:49:26Z,True,"['lists/lists_synapse/train.txt', 'train.py', 'train.py', 'train.sh', 'trainer.py']",True,"['lists/lists_synapse/test_vol.txt', 'test.py', 'test.sh']",88,Unknown
EasyAnimate,aigc-apps,https://github.com/aigc-apps/EasyAnimate,2239,178,ğŸ“º An End-to-End Solution for High-Resolution and Long Video Generation Based on Transformer Diffusion,[],Python,2024-04-11T08:52:50Z,2025-12-08T06:21:23Z,True,"['easyanimate/reward/mps/trainer/models/base_model.py', 'easyanimate/reward/mps/trainer/models/clip_model.py', 'easyanimate/reward/mps/trainer/models/cross_modeling.py', 'easyanimate/video_caption/filter_meta_train.py', 'easyanimate/video_caption/filter_meta_train.py']",True,['easyanimate/vae/ldm/modules/image_degradation/utils/test.png'],96,Apache License 2.0
longformer,allenai,https://github.com/allenai/longformer,2176,288,Longformer: The Long-Document Transformer,[],Python,2020-03-31T21:07:29Z,2025-12-08T13:51:15Z,True,"['scripts/pretrain.py', 'scripts/pretrain.py']",True,"['scripts/test_tpu.py', 'tests/test_integration.py', 'tests/test_readme.py', 'tests/test_sliding_chunks.py', 'tests/test_var_global_attn.py']",139,Apache License 2.0
intel-extension-for-transformers,intel,https://github.com/intel/intel-extension-for-transformers,2169,216,âš¡ Build your chatbot within minutes on your favorite device; offer SOTA compression techniques for LLMs; run LLMs efficiently on Intel Platformsâš¡,"['4-bits', 'autoround', 'chatbot', 'chatpdf', 'gaudi3', 'habana', 'intel-optimized-llamacpp', 'large-language-model', 'llm-cpu', 'llm-inference', 'neural-chat', 'neural-chat-7b', 'rag', 'retrieval', 'speculative-decoding', 'streamingllm']",Python,2022-11-11T05:32:27Z,2025-12-02T02:53:29Z,True,"['.github/workflows/chatbot-finetune-mpt-7b-chat-hpu.yml', '.github/workflows/chatbot-finetune-mpt-7b-chat.yml', '.github/workflows/chatbot_finetuning.yml', 'docs/api_doc/optimization/trainer.rst', 'docs/tutorials/pytorch/question-answering/bert-large-uncased-whole-word-masking-finetuned-squad.ipynb']",True,"['.github/workflows/chatbot-test.yml', '.github/workflows/deploy-test.yml', '.github/workflows/docker/unittest.dockerfile', '.github/workflows/llm-test.yml', '.github/workflows/optimize-test.yml']",56,Apache License 2.0
MambaVision,NVlabs,https://github.com/NVlabs/MambaVision,1933,113,[CVPR 2025] Official PyTorch Implementation of MambaVision: A Hybrid Mamba-Transformer Vision Backbone,"['deep-learning', 'foundation-models', 'huggingface-transformers', 'hybrid-models', 'image-classification', 'instance-segmentation', 'mamba', 'object-detection', 'self-attention', 'semantic-segmentation', 'transformers', 'vision-transformer', 'visual-recognition']",Python,2024-06-10T17:46:08Z,2025-12-10T04:07:27Z,True,"['mambavision/train.py', 'mambavision/train.py', 'mambavision/train.sh', 'object_detection/tools/train.py', 'object_detection/tools/train.py']",True,"['mambavision/dummy_test.py', 'object_detection/tools/analysis_tools/robustness_eval.py', 'object_detection/tools/analysis_tools/test_robustness.py', 'object_detection/tools/deployment/test_torchserver.py', 'object_detection/tools/misc/gen_coco_panoptic_test_info.py']",25,Other
BitNet,kyegomez,https://github.com/kyegomez/BitNet,1894,169,"Implementation of ""BitNet: Scaling 1-bit Transformers for Large Language Models"" in pytorch","['artificial-intelligence', 'deep-neural-networks', 'deeplearning', 'gpt4', 'machine-learning', 'multimodal', 'multimodal-deep-learning']",Python,2023-10-18T16:19:06Z,2025-12-08T16:44:42Z,True,"['train.py', 'train.py']",True,"['.github/workflows/docs_test.yml', '.github/workflows/run_test.yml', '.github/workflows/test.yml', '.github/workflows/testing.yml', '.github/workflows/unit-test.yml']",5,MIT License
Awesome-Backbones,Fafa-DL,https://github.com/Fafa-DL/Awesome-Backbones,1889,275,Integrate deep learning models for image classification | Backbone learning/comparison/magic modification project,"['cnn', 'deep-learning', 'image-classification', 'pytorch', 'pytorch-classification', 'resnet', 'swin-transformer', 'transformer']",Python,2022-01-04T07:00:57Z,2025-12-05T12:22:46Z,True,"['datas/docs/how_to_train.md', 'datas/train.txt', 'tools/train.py', 'tools/train.py', 'utils/train_utils.py']",True,"['datas/test.txt', 'tools/batch_test.py', 'tools/single_test.py', 'tools/video_test.py']",9,Unknown
PVT,whai362,https://github.com/whai362/PVT,1867,254,Official implementation of PVT series,"['backbone', 'detection', 'pvt', 'pvtv2', 'segmentation', 'transformer']",Python,2021-02-24T02:01:37Z,2025-11-30T10:58:46Z,True,"['detection/dist_train.sh', 'detection/train.py', 'detection/train.py', 'dist_train.sh']",True,"['detection/dist_test.sh', 'detection/test.py']",40,Apache License 2.0
ViTPose,ViTAE-Transformer,https://github.com/ViTAE-Transformer/ViTPose,1853,230,"The official repo for [NeurIPS'22] ""ViTPose: Simple Vision Transformer Baselines for Human Pose Estimation"" and [TPAMI'23] ""ViTPose++: Vision Transformer for Generic Body Pose Estimation""","['deep-learning', 'distillation', 'mae', 'pose-estimation', 'pytorch', 'self-supervised-learning', 'vision-transformer']",Python,2022-04-27T01:09:19Z,2025-12-09T03:09:56Z,True,"['docs/en/tutorials/1_finetune.md', 'docs/zh_cn/tutorials/1_finetune.md', 'mmpose/apis/train.py', 'mmpose/apis/train.py', 'tests/data/jhmdb/goalkeeper_training_day_@_7_catch_f_cm_np1_ri_med_0/00001.png']",True,"['mmpose/apis/test.py', 'mmpose/core/evaluation/bottom_up_eval.py', 'mmpose/core/evaluation/mesh_eval.py', 'mmpose/core/evaluation/pose3d_eval.py', 'mmpose/core/evaluation/top_down_eval.py']",106,Apache License 2.0
OminiControl,Yuanshi9815,https://github.com/Yuanshi9815/OminiControl,1848,140,[ICCV 2025 Highlight] OminiControl: Minimal and Universal Control for Diffusion Transformer,[],Python,2024-11-17T08:53:18Z,2025-12-09T10:47:30Z,True,"['omini/train_flux/train_custom.py', 'omini/train_flux/train_custom.py', 'omini/train_flux/train_multi_condition.py', 'omini/train_flux/train_multi_condition.py', 'omini/train_flux/train_spatial_alignment.py']",True,"['assets/test_in.jpg', 'assets/test_out.jpg']",62,Apache License 2.0
Cream,microsoft,https://github.com/microsoft/Cream,1811,239,This is a collection of our NAS and Vision Transformer work.,"['automl', 'efficiency', 'knowledge-distillation', 'nas', 'rpe', 'vision-transformer', 'vit-compression']",Python,2020-10-12T09:30:03Z,2025-12-09T08:03:01Z,True,"['autoformer/supernet_train.py', 'autoformer/supernet_train.py', 'cdarts/cdarts/retrain.py', 'cdarts/cdarts/retrain.py', 'cdarts/cdarts_detection/mmdet/apis/train.py']",True,"['cdarts/cdarts/test.py', 'cdarts/cdarts_detection/mmcv/runner/parallel_test.py', 'cdarts/cdarts_detection/mmdet/datasets/pipelines/test_aug.py', 'cdarts/cdarts_detection/mmdet/models/detectors/test_mixins.py', 'cdarts/cdarts_detection/test.py']",34,MIT License
Keras-TextClassification,yongzhuo,https://github.com/yongzhuo/Keras-TextClassification,1811,402,"ä¸­æ–‡é•¿æ–‡æœ¬åˆ†ç±»ã€çŸ­å¥å­åˆ†ç±»ã€å¤šæ ‡ç­¾åˆ†ç±»ã€ä¸¤å¥å­ç›¸ä¼¼åº¦ï¼ˆChinese Text Classification of Keras NLP, multi-label classify, or sentence classify, long or shortï¼‰ï¼Œå­—è¯å¥å‘é‡åµŒå…¥å±‚ï¼ˆembeddingsï¼‰å’Œç½‘ç»œå±‚ï¼ˆgraphï¼‰æ„å»ºåŸºç±»ï¼ŒFastTextï¼ŒTextCNNï¼ŒCharCNNï¼ŒTextRNN,  RCNN,  DCNN, DPCNN, VDCNN, CRNN, Bert, Xlnet, Albert, Attention, DeepMoji, HAN, èƒ¶å›Šç½‘ç»œ-CapsuleNet, Transformer-encode,  Seq2seq,  SWEM, LEAM, TextGCN","['albert', 'bert', 'capsule', 'charcnn', 'crnn', 'dcnn', 'dpcnn', 'embeddings', 'fasttext', 'han', 'keras', 'keras-textclassification', 'leam', 'nlp', 'rcnn', 'text-classification', 'textcnn', 'transformer', 'vdcnn', 'xlnet']",Python,2019-06-13T15:02:31Z,2025-12-08T05:17:46Z,True,"['keras_textclassification/data/baidu_qa_2019/baike_qa_train.csv', 'keras_textclassification/data/byte_multi_news/train.csv', 'keras_textclassification/data/sim_webank/train.csv', 'keras_textclassification/m00_albert/train.py', 'keras_textclassification/m00_albert/train.py']",True,"['keras_textclassification/data/sim_webank/test.csv', 'test/__init__.py', 'test/fit_generator/__init__.py', 'test/fit_generator/tet_fit_data_generator.py', 'test/fit_generator/tet_fit_data_generator_textcnn.py']",3,MIT License
Show-o,showlab,https://github.com/showlab/Show-o,1809,80,"[ICLR & NeurIPS 2025] Repository for Show-o series, One Single Transformer to Unify Multimodal Understanding and Generation.","['diffusion-models', 'large-language-models', 'multimodal']",Python,2024-08-09T05:26:23Z,2025-12-10T03:16:40Z,True,"['configs/showo_pretraining_stage1.yaml', 'configs/showo_pretraining_stage1.yaml', 'configs/showo_pretraining_stage2.yaml', 'configs/showo_pretraining_stage2.yaml', 'configs/showo_pretraining_stage3.yaml']",True,['show-o2/evaluation/inference_geneval.py'],62,Apache License 2.0
CogView,zai-org,https://github.com/zai-org/CogView,1794,179,"Text-to-Image generation. The repo for NeurIPS 2021 paper ""CogView: Mastering Text-to-Image Generation via Transformers"".","['pretrained-models', 'pytorch', 'text-to-image', 'transformers']",Python,2021-05-25T14:48:31Z,2025-12-09T13:45:40Z,True,"['finetune/__init__.py', 'pretrain_gpt2.py', 'pretrain_gpt2.py', 'pretrained/chinese_sentencepiece/cog-pretrain.model', 'pretrained/chinese_sentencepiece/cog-pretrain.vocab']",True,['test_lmdb.py'],19,Apache License 2.0
How-to-use-Transformers,jsksxs360,https://github.com/jsksxs360/How-to-use-Transformers,1769,209,Transformers åº“å¿«é€Ÿå…¥é—¨æ•™ç¨‹,"['bert', 'classification', 'natural-language-processing', 'ner', 'nlp', 'prompt', 'pytorch', 'qa', 'sentiment-classification', 'summarization', 'transformer', 'transformers', 'translation']",Python,2022-09-19T07:07:34Z,2025-12-09T11:56:30Z,True,"['data/chnsenticorp/train.txt', 'data/afqmc_public/train.json', 'data/china-people-daily-ner-corpus/example.train', 'data/cmrc2018/cmrc2018_train.json', 'train_model_fashionmnist.py']",True,"['data/chnsenticorp/test.txt', 'data/afqmc_public/test.json', 'data/china-people-daily-ner-corpus/example.test']",24,Apache License 2.0
FluxMusic,feizc,https://github.com/feizc/FluxMusic,1712,128,Text-to-Music Generation with Rectified Flow Transformers,[],Python,2024-08-06T09:41:07Z,2025-12-03T11:31:50Z,True,"['audioldm2/clap/open_clip/pretrained.py', 'audioldm2/clap/training/__init__.py', 'audioldm2/clap/training/__pycache__/__init__.cpython-310.pyc', 'audioldm2/clap/training/__pycache__/data.cpython-310.pyc', 'audioldm2/clap/training/audioset_textmap.npy']",True,['test.py'],19,Other
EasyControl,Xiaojiu-z,https://github.com/Xiaojiu-z/EasyControl,1703,127,"Implementation of ""EasyControl: Adding Efficient and Flexible Control for Diffusion Transformer""(ICCV2025)",[],Python,2025-03-06T09:33:30Z,2025-12-09T03:36:33Z,True,"['train/default_config.yaml', 'train/examples/openpose_data/1.png', 'train/examples/openpose_data/2.png', 'train/examples/pose.jsonl', 'train/examples/style.jsonl']",True,"['test_imgs/canny.png', 'test_imgs/depth.png', 'test_imgs/ghibli.png', 'test_imgs/inpainting.png', 'test_imgs/openpose.png']",23,Apache License 2.0
TransGAN,VITA-Group,https://github.com/VITA-Group/TransGAN,1688,204,"[NeurIPSâ€˜2021] ""TransGAN: Two Pure Transformers Can Make One Strong GAN, and That Can Scale Up"", Yifan Jiang, Shiyu Chang, Zhangyang Wang","['gan', 'pytorch', 'transformer', 'transformer-encoder', 'transformer-models']",Python,2021-02-10T18:11:54Z,2025-11-25T10:54:36Z,True,"['exps/celeba_hq_256_train.py', 'exps/celeba_hq_256_train.py', 'exps/church_256_train.py', 'exps/church_256_train.py', 'exps/cifar_train.py']",True,"['exps/celeba_hq_256_test.py', 'exps/cifar_test.py', 'test.py']",15,Other
titans-pytorch,lucidrains,https://github.com/lucidrains/titans-pytorch,1655,158,"Unofficial implementation of Titans, SOTA memory for transformers, in Pytorch","['artificial-intelligence', 'deep-learning', 'long-term-memory', 'test-time-training']",Python,2025-01-08T15:26:27Z,2025-12-10T05:01:11Z,True,"['train_implicit_mlp_attn.py', 'train_implicit_mlp_attn.py', 'train_mac.py', 'train_mac.py']",True,"['.github/workflows/test.yaml', 'tests/test_titans.py']",31,MIT License
FireRedASR,FireRedTeam,https://github.com/FireRedTeam/FireRedASR,1654,149,"Open-source industrial-grade ASR models supporting Mandarin, Chinese dialects and English, achieving a new SOTA on public Mandarin ASR benchmarks, while also offering outstanding singing lyrics recognition capability.","['asr', 'automatic-speech-recognition', 'conformer', 'industrial-grade', 'llm', 'multimodal-llm', 'open-source', 'speech-recognition', 'speechllm', 'transformer']",Python,2025-01-24T11:25:35Z,2025-12-09T09:31:00Z,True,"['examples/pretrained_models', 'pretrained_models/readme.md']",True,"['examples/wav/test_meeting_t0000000001_s00000.wav', 'examples/wav/test_net_y0000000000_-ktkhdz2fb8_s00000.wav']",69,Apache License 2.0
MetaTransformer,invictus717,https://github.com/invictus717/MetaTransformer,1644,117,Meta-Transformer for Unified Multimodal Learning,"['artificial-intelligence', 'computer-vision', 'foundationmodel', 'machine-learning', 'multimedia', 'multimodal', 'transformers']",Python,2023-07-08T12:40:54Z,2025-12-05T03:19:08Z,True,"['audio/src/traintest.py', 'autonomousdriving/data/kitti/imagesets/train.txt', 'autonomousdriving/data/lyft/imagesets/train.txt', 'autonomousdriving/data/once/imagesets/train.txt', 'autonomousdriving/data/waymo/imagesets/train.txt']",True,"['audio/src/traintest.py', 'autonomousdriving/data/kitti/imagesets/test.txt', 'autonomousdriving/data/lyft/imagesets/test.txt', 'autonomousdriving/data/once/imagesets/test.txt', 'autonomousdriving/pcdet/datasets/kitti/kitti_eval.py']",4,Apache License 2.0
robotics_transformer,google-research,https://github.com/google-research/robotics_transformer,1642,189,,[],Python,2022-12-05T00:39:23Z,2025-12-10T02:30:22Z,True,"['film_efficientnet/pretrained_efficientnet_encoder.py', 'film_efficientnet/pretrained_efficientnet_encoder_test.py', 'trained_checkpoints/rt1main/assets/metadata.textproto', 'trained_checkpoints/rt1main/checkpoint', 'trained_checkpoints/rt1main/ckpt-424760.data-00000-of-00001']",True,"['film_efficientnet/film_conditioning_layer_test.py', 'film_efficientnet/film_efficientnet_encoder_test.py', 'film_efficientnet/preprocessors_test.py', 'film_efficientnet/pretrained_efficientnet_encoder_test.py', 'sequence_agent_test.py']",23,Apache License 2.0
torchdistill,yoshitomo-matsubara,https://github.com/yoshitomo-matsubara/torchdistill,1574,140,"A coding-free framework built on PyTorch for reproducible deep learning studies. PyTorch Ecosystem. ğŸ†26 knowledge distillation methods presented at CVPR, ICLR, ECCV, NeurIPS, ICCV, etc are implemented so far. ğŸ Trained models, training logs and configurations are available for ensuring the reproducibiliy and benchmark.","['amazon-sagemaker-lab', 'cifar10', 'cifar100', 'coco', 'colab-notebook', 'glue', 'google-colab', 'image-classification', 'imagenet', 'knowledge-distillation', 'natural-language-processing', 'nlp', 'object-detection', 'pascal-voc', 'pytorch', 'pytorch-ecosystem', 'semantic-segmentation', 'text-classification', 'transformer']",Python,2019-12-18T17:40:32Z,2025-12-08T03:42:40Z,True,"['demo/cifar_training.ipynb', 'demo/glue_finetuning_and_submission.ipynb', 'torchdistill/core/training.py']",True,"['examples/torchvision/coco/eval.py', 'examples/torchvision/utils/eval.py', 'tests/config_test.py', 'tests/core_test.py', 'tests/registry_test.py']",0,MIT License
safe-rlhf,PKU-Alignment,https://github.com/PKU-Alignment/safe-rlhf,1563,128,Safe RLHF: Constrained Value Alignment via Safe Reinforcement Learning from Human Feedback,"['ai-safety', 'alpaca', 'beaver', 'datasets', 'deepspeed', 'gpt', 'large-language-models', 'llama', 'llm', 'llms', 'reinforcement-learning', 'reinforcement-learning-from-human-feedback', 'rlhf', 'safe-reinforcement-learning', 'safe-reinforcement-learning-from-human-feedback', 'safe-rlhf', 'safety', 'transformer', 'transformers', 'vicuna']",Python,2023-05-15T11:47:08Z,2025-12-08T09:07:03Z,True,"['safe_rlhf/algorithms/dpo/trainer.py', 'safe_rlhf/algorithms/ppo/trainer.py', 'safe_rlhf/algorithms/ppo_lag/trainer.py', 'safe_rlhf/algorithms/ppo_reward_shaping/trainer.py', 'safe_rlhf/configs/ds_train_config_template.json']",True,"['safe_rlhf/evaluate/bigbench/eval.py', 'safe_rlhf/evaluate/gpt4/eval.py']",18,Apache License 2.0
Semi-supervised-learning,microsoft,https://github.com/microsoft/Semi-supervised-learning,1553,204,A Unified Semi-Supervised Learning Codebase (NeurIPS'22),"['audio-classification', 'classification', 'computer-vision', 'deep-learning', 'low-resource', 'machine-learning', 'natural-language-processing', 'pytorch', 'semi-supervised-learning', 'semisupervised-learning', 'transformer']",Python,2022-05-05T06:24:15Z,2025-12-03T15:04:47Z,True,"['semilearn/lighting/trainer.py', 'train.py', 'train.py']",True,['eval.py'],1,MIT License
RoboticsDiffusionTransformer,thu-ml,https://github.com/thu-ml/RoboticsDiffusionTransformer,1549,145,RDT-1B: a Diffusion Foundation Model for Bimanual Manipulation,[],Python,2024-10-07T10:08:30Z,2025-12-09T06:06:29Z,True,"['configs/finetune_datasets.json', 'configs/finetune_sample_weights.json', 'configs/pretrain_datasets.json', 'configs/pretrain_datasets.json', 'configs/pretrain_sample_weights.json']",True,['docs/test_6drot.py'],40,MIT License
4D-Humans,shubham-goel,https://github.com/shubham-goel/4D-Humans,1486,143,4DHumans: Reconstructing and Tracking Humans with Transformers,['3d-reconstruction'],Python,2023-05-31T21:05:33Z,2025-12-10T00:22:26Z,True,"['fetch_training_data.sh', 'fetch_training_data.sh', 'hmr2/configs_hydra/train.yaml', 'hmr2/configs_hydra/trainer/cpu.yaml', 'hmr2/configs_hydra/trainer/ddp.yaml']",True,['eval.py'],35,MIT License
CodeTF,salesforce,https://github.com/salesforce/CodeTF,1479,97,CodeTF: One-stop Transformer Library for State-of-the-art Code LLM,"['ai4code', 'ai4se', 'code-generation', 'code-intelligence', 'code-learning-datasets', 'code-representation-learning', 'code-understanding', 'human-eval', 'multilingual-parsers', 'transformers', 'tree-sitter']",Python,2023-05-02T05:05:27Z,2025-11-25T10:39:34Z,True,"['codetf/configs/training/causal_lm.yaml', 'codetf/configs/training/codet5.yaml', 'codetf/trainer/base_trainer.py', 'codetf/trainer/causal_lm_trainer.py', 'codetf/trainer/codet5_trainer.py']",True,"['test_code_utilities/__init__.py', 'test_code_utilities/test_extract_code_attributes.py', 'test_code_utilities/test_parse_code.py', 'test_code_utilities/test_remove_comments.py', 'test_code_utilities/test_variable_renaming.py']",28,Apache License 2.0
long_llama,CStanKonrad,https://github.com/CStanKonrad/long_llama,1463,85,LongLLaMA is a large language model capable of handling long contexts. It is based on OpenLLaMA and fine-tuned with the Focused Transformer (FoT) method.,[],Python,2023-07-06T14:54:15Z,2025-11-21T13:13:43Z,True,"['fot_continued_pretraining/easylm/__init__.py', 'fot_continued_pretraining/easylm/bpt.py', 'fot_continued_pretraining/easylm/checkpoint.py', 'fot_continued_pretraining/easylm/data.py', 'fot_continued_pretraining/easylm/jax_utils.py']",True,['fot_continued_pretraining/configs/setup_test.json'],18,Apache License 2.0
MaskDINO,IDEA-Research,https://github.com/IDEA-Research/MaskDINO,1457,149,"[CVPR 2023] Official implementation of the paper ""Mask DINO: Towards A Unified Transformer-based Framework for Object Detection and Segmentation""","['instance-segmentation', 'object-detection', 'panoptic-segmentation', 'semantic-segmentation']",Python,2022-06-06T16:02:01Z,2025-12-09T16:10:49Z,True,"['tools/convert-pretrained-swin-model-to-d2.py', 'train_net.py', 'train_net.py']",True,"['maskdino/modeling/pixel_decoder/ops/test.py', 'maskdino/test_time_augmentation.py', 'tools/evaluate_coco_boundary_ap.py', 'tools/evaluate_pq_for_semantic_segmentation.py']",64,Apache License 2.0
octo,octo-models,https://github.com/octo-models/octo,1455,240,Octo is a transformer-based robot policy trained on a diverse mix of 800k robot trajectories.,[],Python,2023-12-13T09:58:56Z,2025-12-10T02:38:23Z,True,"['examples/01_inference_pretrained.ipynb', 'examples/02_finetune_new_observation_action.py', 'examples/03_eval_finetuned.py', 'examples/04_eval_finetuned_on_robot.py', 'octo/utils/train_callbacks.py']",True,"['tests/debug_config.py', 'tests/debug_dataset/bridge_dataset/1.0.0/bridge_dataset-train.tfrecord-00000-of-00001', 'tests/debug_dataset/bridge_dataset/1.0.0/bridge_dataset-val.tfrecord-00000-of-00001', 'tests/debug_dataset/bridge_dataset/1.0.0/dataset_info.json', 'tests/debug_dataset/bridge_dataset/1.0.0/features.json']",92,MIT License
ViT-Adapter,czczup,https://github.com/czczup/ViT-Adapter,1447,151,[ICLR 2023 Spotlight] Vision Transformer Adapter for Dense Predictions,"['adapter', 'object-detection', 'semantic-segmentation', 'vision-transformer']",Python,2022-05-16T17:32:59Z,2025-12-07T21:42:16Z,True,"['detection/dist_train.sh', 'detection/slurm_train.sh', 'detection/train.py', 'detection/train.py', 'segmentation/dist_train.sh']",True,"['detection/dist_test.sh', 'detection/ops/test.py', 'detection/slurm_test.sh', 'detection/test.py', 'segmentation/dist_test.sh']",81,Other
HAT,XPixelGroup,https://github.com/XPixelGroup/HAT,1432,171,CVPR2023 - Activating More Pixels in Image Super-Resolution Transformer TPAMI - HAT: Hybrid Attention Transformer for Image Restoration,[],Python,2022-04-27T11:44:25Z,2025-12-08T03:12:29Z,True,"['experiments/pretrained_models/readme.md', 'hat/train.py', 'hat/train.py', 'options/test/hat-l_srx2_imagenet-pretrain.yml', 'options/test/hat-l_srx3_imagenet-pretrain.yml']",True,"['hat/test.py', 'options/test/hat-l_srx2_imagenet-pretrain.yml', 'options/test/hat-l_srx3_imagenet-pretrain.yml', 'options/test/hat-l_srx4_imagenet-pretrain.yml', 'options/test/hat-s_srx2.yml']",106,Apache License 2.0
MapTR,hustvl,https://github.com/hustvl/MapTR,1427,229,[ICLR'23 Spotlight & ECCV'24 & IJCV'24] MapTR: Structured Modeling and Learning for Online Vectorized HD Map Construction,"['autonomous-driving', 'bev', 'end-to-end', 'iclr2023', 'online-hdmap-construction', 'real-time', 'shape-representation', 'transformer', 'vectorized-hdmap']",Python,2022-07-28T02:20:43Z,2025-12-09T11:14:04Z,True,"['docs/train_eval.md', 'docs/train_eval.md', 'mmdetection3d/.dev_scripts/train_benchmark.sh', 'mmdetection3d/.dev_scripts/train_benchmark.sh', 'mmdetection3d/configs/fcos3d/fcos3d_r101_caffe_fpn_gn-head_dcn_2x8_1x_nus-mono3d_finetune.py']",True,"['mmdetection3d/.dev_scripts/gen_benchmark_script.py', 'mmdetection3d/.dev_scripts/test_benchmark.sh', 'mmdetection3d/mmdet3d/apis/test.py', 'mmdetection3d/mmdet3d/core/evaluation/indoor_eval.py', 'mmdetection3d/mmdet3d/core/evaluation/kitti_utils/eval.py']",134,MIT License
Megatron-DeepSpeed,bigscience-workshop,https://github.com/bigscience-workshop/Megatron-DeepSpeed,1426,228,"Ongoing research training transformer language models at scale, including: BERT & GPT-2",[],Python,2021-07-02T17:40:35Z,2025-11-26T06:51:29Z,True,"['examples/curriculum_learning/pretrain_gpt_cl.sh', 'examples/curriculum_learning/pretrain_gpt_cl.sh', 'examples/finetune_mnli_distributed.sh', 'examples/finetune_race_distributed.sh', 'examples/pretrain_bert.sh']",True,"['examples/evaluate_ict_zeroshot_nq.sh', 'examples/evaluate_zeroshot_gpt.sh', 'megatron/data/test/test_indexed_dataset.py', 'megatron/data/test/test_preprocess_data.sh', 'megatron/fused_kernels/tests/__init__.py']",123,Other
spacy-transformers,explosion,https://github.com/explosion/spacy-transformers,1402,176,"ğŸ›¸ Use pretrained transformers like BERT, XLNet and GPT-2 in spaCy","['bert', 'google', 'gpt-2', 'huggingface', 'language-model', 'machine-learning', 'natural-language-processing', 'natural-language-understanding', 'nlp', 'openai', 'pytorch', 'pytorch-model', 'spacy', 'spacy-extension', 'spacy-pipeline', 'transfer-learning', 'xlnet']",Python,2019-07-26T19:12:34Z,2025-11-19T10:46:06Z,True,['build-constraints.txt'],True,"['.github/workflows/tests.yml', 'spacy_transformers/tests/__init__.py', 'spacy_transformers/tests/enable_gpu.py', 'spacy_transformers/tests/regression/__init__.py', 'spacy_transformers/tests/regression/test_spacy_issue6401.py']",0,MIT License
poolformer,sail-sg,https://github.com/sail-sg/poolformer,1356,118,PoolFormer: MetaFormer Is Actually What You Need for Vision (CVPR 2022 Oral),"['image-classification', 'mlp', 'pooling', 'pytorch', 'transformer']",Python,2021-11-22T02:47:03Z,2025-11-17T03:09:04Z,True,"['detection/dist_train.sh', 'detection/mmdet_custom/apis/train.py', 'detection/mmdet_custom/apis/train.py', 'detection/train.py', 'detection/train.py']",True,"['detection/dist_test.sh', 'detection/test.py', 'segmentation/dist_test.sh', 'segmentation/test.py', 'segmentation/tools/deploy_test.py']",14,Apache License 2.0
gansformer,dorarad,https://github.com/dorarad/gansformer,1341,151,Generative Adversarial Transformers,"['attention', 'compositionality', 'gans', 'generative-adversarial-networks', 'image-generation', 'scene-generation', 'transformers']",Python,2021-03-01T13:39:07Z,2025-11-20T17:21:05Z,True,"['pretrained_networks.py', 'pytorch_version/torch_utils/training_stats.py', 'pytorch_version/torch_utils/training_stats.py', 'pytorch_version/training/__init__.py', 'pytorch_version/training/dataset.py']",True,['test_nvcc.cu'],15,MIT License
bert4torch,Tongjilibo,https://github.com/Tongjilibo/bert4torch,1332,168,An elegent pytorch implement of transformers,"['belle', 'bert', 'bert4keras', 'bert4torch', 'chatglm', 'large-language-models', 'llama', 'llm', 'named-entity-recognition', 'nlp', 'pytorch', 'relation-extraction', 'seq2seq', 'text-classification', 'transformers']",Python,2022-03-12T16:23:44Z,2025-12-07T17:34:38Z,True,"['bert4torch/trainer/__init__.py', 'bert4torch/trainer/dpo_trainer.py', 'bert4torch/trainer/ppo_trainer.py', 'bert4torch/trainer/ptuningv2_trainer.py', 'bert4torch/trainer/sequence_classification_trainer.py']",True,"['examples/basic/others/basic_test_openai_client.py', 'examples/basic/others/basic_test_parallel_apply.py', 'test/llm/test_bloom.py', 'test/llm/test_falcon.py', 'test/llm/test_glm.py']",2,MIT License
Retinexformer,caiyuanhao1998,https://github.com/caiyuanhao1998/Retinexformer,1327,109,"""Retinexformer: One-stage Retinex-based Transformer for Low-light Image Enhancement"" (ICCV 2023) & (NTIRE 2024 Runner-Up)","['basicsr', 'detection', 'iccv2023', 'image-restoration', 'low-light-enhance', 'low-light-enhancement', 'low-light-enhancer', 'low-light-image-enhancement', 'low-light-vision', 'nighttime-enhancement', 'ntire', 'object-detection', 'transformer']",Python,2023-07-15T10:53:06Z,2025-12-10T01:46:13Z,True,"['basicsr/data/meta_info/meta_info_vimeo90k_train_gt.txt', 'basicsr/data/meta_info/meta_info_vimeo90k_train_gt.txt', 'basicsr/train.py', 'basicsr/train.py', 'train_multigpu.sh']",True,"['enhancement/test_from_dataset.py', 'basicsr/data/meta_info/meta_info_reds4_test_gt.txt', 'basicsr/data/meta_info/meta_info_redsofficial4_test_gt.txt', 'basicsr/data/meta_info/meta_info_redsval_official_test_gt.txt', 'basicsr/data/meta_info/meta_info_vimeo90k_test_gt.txt']",2,MIT License
unimatch,autonomousvision,https://github.com/autonomousvision/unimatch,1317,131,"[TPAMI'23] Unifying Flow, Stereo and Depth Estimation","['correspondence', 'cross-attention', 'depth', 'matching', 'optical-flow', 'stereo', 'transformer', 'unified-model']",Python,2022-11-04T04:47:31Z,2025-12-05T07:03:35Z,True,"['dataloader/depth/download_demon_train.sh', 'dataloader/depth/prepare_demon_train.py', 'dataloader/depth/prepare_demon_train.py', 'dataloader/depth/scannet_banet_train_pairs.txt', 'dataloader/depth/scannet_banet_train_pairs.txt']",True,"['dataloader/depth/download_demon_test.sh', 'dataloader/depth/prepare_demon_test.py', 'dataloader/depth/scannet_banet_test_pairs.txt', 'evaluate_depth.py', 'evaluate_flow.py']",12,MIT License
SDT,dailenson,https://github.com/dailenson/SDT,1301,106,This repository is the official implementation of Disentangling Writer and Character Styles for Handwriting Generation (CVPR 2023),"['computer-vision', 'contrastive-learning', 'deep-learning', 'generative-models', 'gmm', 'handwriting-generation', 'multimodal', 'pytorch-implementation', 'transformer']",Python,2023-03-22T01:53:13Z,2025-12-09T10:46:35Z,True,"['train.py', 'train.py', 'trainer/trainer.py']",True,['test.py'],74,MIT License
WFGY,onestardao,https://github.com/onestardao/WFGY,1270,106,"WFGY 2.0. Semantic Reasoning Engine for LLMs (MIT). Fixes RAG/OCR drift, collapse & â€œghost matchesâ€ via symbolic overlays + logic patches. Autoboot; OneLine & Flagship. â­ Star if you explore semantic RAG or hallucination mitigation.","['ai-interpretability', 'alignment', 'embedding', 'hallucination', 'knowledge-graph', 'llm', 'open-source', 'rag', 'reasoning', 'semantic-engine', 'semantic-inference', 'semantic-residue', 'semantic-resonance', 'semantic-tension', 'symbolic-reasoning', 'transformer', 'txt-os', 'wanfaguiyi']",Python,2025-06-04T13:45:14Z,2025-12-09T03:20:05Z,True,['problemmap/patterns/pattern_symbolic_constraint_unlock.md'],True,"['os/images/kb_boundary_test_demo.gif', 'problemmap/globalfixmap/opsdeploy/postmortem_and_regression_tests.md', 'benchmarks/benchmark-vs-gpt5/gpt5_vs_wfgy_benchmark_20250810.png', 'benchmarks/semantic-drift-demo/data/test_prompts.json', 'benchmarks/semantic-drift-demo/scripts/run_eval.py']",2,MIT License
contextualized-topic-models,MilaNLProc,https://github.com/MilaNLProc/contextualized-topic-models,1253,151,"A python package to run contextualized topic modeling. CTMs combine contextualized embeddings (e.g., BERT) with topic models to get coherent topics. Published at EACL and ACL 2021 (Bianchi et al.). ","['bert', 'embeddings', 'multilingual-models', 'multilingual-topic-models', 'neural-topic-models', 'nlp', 'nlp-library', 'nlp-machine-learning', 'text-as-data', 'topic-coherence', 'topic-modeling', 'transformer']",Python,2020-04-04T19:11:29Z,2025-12-10T05:00:44Z,True,['contextualized_topic_models/data/gnews/train.txt.pkl'],True,"['tests/__init__.py', 'tests/test_contextualized_topic_models.py', 'tests/test_measures.py']",8,MIT License
PaddleViT,BR-IDL,https://github.com/BR-IDL/PaddleViT,1235,327,:robot: PaddleViT: State-of-the-art Visual Transformer and MLP Models for PaddlePaddle 2.0+,"['classification', 'computer-vision', 'cv', 'deep-learning', 'detection', 'encoder-decoder', 'gan', 'mlp', 'object-detection', 'paddlepaddle', 'segmentation', 'semantic-segmentation', 'transformer', 'vit']",Python,2021-08-30T06:47:47Z,2025-11-07T02:14:01Z,True,"['gan/styleformer/run_train.sh', 'gan/styleformer/run_train_multi.sh', 'gan/styleformer/run_train_multi.sh', 'gan/transgan/run_train.sh', 'image_classification/botnet/run_train.sh']",True,"['image_classification/cait/tests/__init__.py', 'image_classification/cait/tests/test_cait.py', 'image_classification/convmixer/tests/__init__.py', 'image_classification/convmixer/tests/test_onecyclelr.py', 'image_classification/crossvit/port_weights/load_pytorch_weights_multi_test.py']",39,Apache License 2.0
Transformers4Rec,NVIDIA-Merlin,https://github.com/NVIDIA-Merlin/Transformers4Rec,1231,155,Transformers4Rec is a flexible and efficient library for sequential and session-based recommendation and works with PyTorch.,"['bert', 'gtp', 'huggingface', 'language-model', 'nlp', 'pytorch', 'recommender-system', 'recsys', 'seq2seq', 'session-based-recommendation', 'tabular-data', 'transformer', 'xlnet']",Python,2021-04-14T19:20:29Z,2025-12-05T07:33:21Z,True,"['docs/source/multi_gpu_train.md', 'docs/source/training_eval.md', 'docs/source/training_eval.md', 'examples/end-to-end-session-based/03-session-based-yoochoose-multigpu-training-pyt.ipynb', 'tests/unit/config/test_trainer.py']",True,"['ci/build_and_test.sh', 'ci/test_integration.sh', 'ci/test_unit.sh', 'requirements/test.txt', 'tests/.coveragerc']",95,Apache License 2.0
sockeye,awslabs,https://github.com/awslabs/sockeye,1218,321,Sequence-to-sequence framework with a focus on Neural Machine Translation based on PyTorch,"['attention-is-all-you-need', 'attention-mechanism', 'attention-model', 'deep-learning', 'deep-neural-networks', 'encoder-decoder', 'machine-learning', 'machine-translation', 'neural-machine-translation', 'pytorch', 'seq2seq', 'sequence-to-sequence', 'sequence-to-sequence-models', 'sockeye', 'transformer', 'transformer-architecture', 'transformer-network', 'translation']",Python,2017-06-08T07:44:30Z,2025-11-30T15:51:30Z,True,"['docs/training.md', 'sockeye/train.py', 'sockeye/train.py', 'sockeye/training.py']",True,"['pytest.ini', 'sockeye/test_utils.py', 'sockeye_contrib/benchmark/benchmark_to_output.py', 'sockeye_contrib/benchmark/benchmark_to_percentiles.py', 'sockeye_contrib/vistools/pytest.ini']",12,Apache License 2.0
Neighborhood-Attention-Transformer,SHI-Labs,https://github.com/SHI-Labs/Neighborhood-Attention-Transformer,1163,88,"Neighborhood Attention Transformer, arxiv 2022 / CVPR 2023. Dilated Neighborhood Attention Transformer, arxiv 2022","['neighborhood-attention', 'pytorch']",Python,2022-04-14T06:40:50Z,2025-12-05T05:26:46Z,True,"['classification/dist_train.sh', 'classification/train.py', 'classification/train.py', 'detection/dist_train.sh', 'detection/train.py']",True,"['detection/dist_test.sh', 'detection/test.py', 'segmentation/dist_test.sh', 'segmentation/test.py']",5,MIT License
TransformerTTS,spring-media,https://github.com/spring-media/TransformerTTS,1156,222,ğŸ¤–ğŸ’¬ Transformer TTS: Implementation of a non-autoregressive Transformer based neural network for text to speech.,"['axelspringerai', 'deep-learning', 'python', 'tensorflow', 'text-to-speech', 'tts']",Python,2020-03-26T14:21:36Z,2025-11-11T18:59:53Z,True,"['config/training_config.yaml', 'config/training_config.yaml', 'create_training_data.py', 'create_training_data.py', 'train_aligner.py']",True,"['aligner_test_sentences.txt', 'test_sentences.txt', 'tests/__init__.py', 'tests/test_char_tokenizer.py', 'tests/test_config.yaml']",50,Other
detoxify,unitaryai,https://github.com/unitaryai/detoxify,1151,135,"Trained models & code to predict toxic comments on all 3 Jigsaw Toxic Comment Challenges. Built using âš¡ Pytorch Lightning and ğŸ¤— Transformers. For access to our API, please email us at contact@unitary.ai.","['bert', 'bert-model', 'hate-speech', 'hate-speech-detection', 'hatespeech', 'huggingface', 'huggingface-transformers', 'kaggle-competition', 'nlp', 'pytorch-lightning', 'sentence-classification', 'toxic-comment-classification', 'toxic-comments', 'toxicity', 'toxicity-classification']",Python,2020-09-23T15:24:21Z,2025-12-09T12:10:22Z,True,"['tests/dummy_data/jigsaw-toxic-comment-classification-challenge/train.csv', 'tests/test_trainer.py', 'train.py', 'train.py']",True,"['.github/workflows/ci-testing.yml', 'tests/__init__.py', 'tests/dummy_data/jigsaw-toxic-comment-classification-challenge/test.csv', 'tests/dummy_data/jigsaw-toxic-comment-classification-challenge/train.csv', 'tests/requirements.txt']",38,Apache License 2.0
GPT2-NewsTitle,liucongg,https://github.com/liucongg/GPT2-NewsTitle,1116,181,Chinese NewsTitle Generation Project by GPT2.å¸¦æœ‰è¶…çº§è¯¦ç»†æ³¨é‡Šçš„ä¸­æ–‡GPT2æ–°é—»æ ‡é¢˜ç”Ÿæˆé¡¹ç›®ã€‚,"['chinese', 'gpt2', 'news-summarization', 'nlp', 'text-generation', 'torch', 'transformer']",Python,2020-12-16T07:16:21Z,2025-12-09T10:07:07Z,True,"['image/train_loss.png', 'image/train_loss.png', 'train.py', 'train.py']",True,['image/test_loss.png'],21,Apache License 2.0
MST,caiyuanhao1998,https://github.com/caiyuanhao1998/MST,1114,86,"A toolbox for spectral compressive imaging reconstruction including MST (CVPR 2022), CST (ECCV 2022), DAUHST (NeurIPS 2022), BiSCI (NeurIPS 2023), HDNet (CVPR 2022), MST++ (CVPRW 2022), etc.","['binarized-neural-networks', 'bnn', 'hyperspectral-images', 'image-restoration', 'ntire', 'qnn', 'snapshot-compressive-imaging', 'spectral-reconstruction', 'transformer']",Python,2022-03-04T13:38:48Z,2025-12-09T04:16:30Z,True,"['real/train_code/__pycache__/dataset.cpython-36.pyc', 'real/train_code/__pycache__/dataset.cpython-36.pyc', 'real/train_code/__pycache__/option.cpython-36.pyc', 'real/train_code/__pycache__/option.cpython-36.pyc', 'real/train_code/__pycache__/template.cpython-36.pyc']",True,"['real/test_code/__pycache__/utils.cpython-36.pyc', 'real/test_code/architecture/admm_net.py', 'real/test_code/architecture/birnat.py', 'real/test_code/architecture/bisrnet.py', 'real/test_code/architecture/cst.py']",2,MIT License
SETR,fudan-zvg,https://github.com/fudan-zvg/SETR,1103,148,[CVPR 2021 & IJCV 2024] Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers,[],Python,2020-12-30T10:18:45Z,2025-12-05T13:26:19Z,True,"['docs/tutorials/training_tricks.md', 'docs/tutorials/training_tricks.md', 'hlg-detection/configs/cascade_rcnn/cascade_mask_rcnn_r101_caffe_fpn_mstrain_3x_coco.py', 'hlg-detection/configs/cascade_rcnn/cascade_mask_rcnn_r101_caffe_fpn_mstrain_3x_coco.py', 'hlg-detection/configs/cascade_rcnn/cascade_mask_rcnn_r101_fpn_mstrain_3x_coco.py']",True,"['hlg-detection/configs/centripetalnet/centripetalnet_hourglass104_mstest_16x6_210e_coco.py', 'hlg-detection/configs/cornernet/cornernet_hourglass104_mstest_10x5_210e_coco.py', 'hlg-detection/configs/cornernet/cornernet_hourglass104_mstest_32x3_210e_coco.py', 'hlg-detection/configs/cornernet/cornernet_hourglass104_mstest_8x6_210e_coco.py', 'hlg-detection/mmdet/apis/test.py']",16,MIT License
SwissArmyTransformer,THUDM,https://github.com/THUDM/SwissArmyTransformer,1098,98,SwissArmyTransformer is a flexible and powerful library to develop your own Transformer variants.,"['pretrained-models', 'pytorch', 'transformer']",Python,2021-10-06T12:30:39Z,2025-12-09T13:46:30Z,True,"['examples/bert/finetune_bert_adapter_boolq.py', 'examples/bert/finetune_bert_boolq.py', 'examples/bert/finetune_distill_boolq.py', 'examples/bert/scripts/finetune_adapter_boolq.sh', 'examples/bert/scripts/finetune_boolq.sh']",True,"['examples/t5/test_t5.py', 'examples/yolos/datasets_/coco_eval.py', 'tests/deepspeed_test.json', 'tests/sbatch_launch.sh', 'tests/single_launch.sh']",42,Apache License 2.0
