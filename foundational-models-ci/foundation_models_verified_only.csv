name,owner,url,stars,forks,description,topics,language,created_at,updated_at,has_training,training_files_sample,has_testing,testing_files_sample,open_issues,license
transformers,huggingface,https://github.com/huggingface/transformers,153668,31358,"ðŸ¤— Transformers: the model-definition framework for state-of-the-art machine learning models in text, vision, audio, and multimodal models, for both inference and training. ","['audio', 'deep-learning', 'deepseek', 'gemma', 'glm', 'hacktoberfest', 'llm', 'machine-learning', 'model-hub', 'natural-language-processing', 'nlp', 'pretrained-models', 'python', 'pytorch', 'pytorch-transformers', 'qwen', 'speech-recognition', 'transformer', 'vlm']",Python,2018-10-29T13:56:00Z,2025-12-10T05:13:19Z,True,"['docs/source/ar/trainer.md', 'docs/source/ar/training.md', 'docs/source/de/training.md', 'docs/source/en/hpo_train.md', 'docs/source/en/internal/trainer_utils.md']",True,"['.circleci/parse_test_outputs.py', '.github/workflows/benchmark_v2.yml', '.github/workflows/benchmark_v2_a10_caller.yml', '.github/workflows/benchmark_v2_mi325_caller.yml', '.github/workflows/check_failed_tests.yml']",2142,Apache License 2.0
pytorch-image-models,huggingface,https://github.com/huggingface/pytorch-image-models,35974,5082,"The largest collection of PyTorch image encoders / backbones. Including train, eval, inference, export scripts, and pretrained weights -- ResNet, ResNeXT, EfficientNet, NFNet, Vision Transformer (ViT), MobileNetV4, MobileNet-V3 & V2, RegNet, DPN, CSPNet, Swin Transformer, MaxViT, CoAtNet, ConvNeXt, and more","['augmix', 'convnext', 'distributed-training', 'efficientnet', 'image-classification', 'imagenet', 'maxvit', 'mixnet', 'mobile-deep-learning', 'mobilenet-v2', 'mobilenetv3', 'nfnets', 'normalization-free-training', 'optimizer', 'pretrained-models', 'pretrained-weights', 'pytorch', 'randaugment', 'resnet', 'vision-transformer-models']",Python,2019-02-02T05:51:12Z,2025-12-10T04:56:40Z,True,"['distributed_train.sh', 'hfdocs/source/training_script.mdx', 'hfdocs/source/training_script.mdx', 'results/benchmark-train-amp-nchw-pt112-cu113-rtx3090.csv', 'results/benchmark-train-amp-nhwc-pt112-cu113-rtx3090.csv']",True,"['.github/workflows/tests.yml', 'tests/__init__.py', 'tests/test_layers.py', 'tests/test_layers_drop.py', 'tests/test_layers_pool.py']",72,Apache License 2.0
mmdetection,open-mmlab,https://github.com/open-mmlab/mmdetection,32143,9828,OpenMMLab Detection Toolbox and Benchmark,"['cascade-rcnn', 'convnext', 'detr', 'fast-rcnn', 'faster-rcnn', 'glip', 'grounding-dino', 'instance-segmentation', 'mask-rcnn', 'object-detection', 'panoptic-segmentation', 'pytorch', 'retinanet', 'rtmdet', 'semisupervised-learning', 'ssd', 'swin-transformer', 'transformer', 'vision-transformer', 'yolo']",Python,2018-08-22T07:06:06Z,2025-12-09T13:47:45Z,True,"['.dev_scripts/batch_train_list.txt', '.dev_scripts/batch_train_list.txt', '.dev_scripts/benchmark_train.py', '.dev_scripts/benchmark_train.py', '.dev_scripts/benchmark_train_models.txt']",True,"['.circleci/test.yml', '.dev_scripts/batch_test_list.py', '.dev_scripts/benchmark_filter.py', '.dev_scripts/benchmark_full_models.txt', '.dev_scripts/benchmark_inference_fps.py']",1944,Apache License 2.0
vit-pytorch,lucidrains,https://github.com/lucidrains/vit-pytorch,24616,3459,"Implementation of Vision Transformer, a simple way to achieve SOTA in vision classification with only a single transformer encoder, in Pytorch","['artificial-intelligence', 'attention-mechanism', 'computer-vision', 'image-classification', 'transformers']",Python,2020-10-03T22:47:24Z,2025-12-10T04:25:51Z,True,"['train_vit_decorr.py', 'train_vit_decorr.py']",True,"['.github/workflows/python-test.yml', 'tests/.ds_store', 'tests/test_vit.py']",142,MIT License
minGPT,karpathy,https://github.com/karpathy/minGPT,23117,3029,A minimal PyTorch re-implementation of the OpenAI GPT (Generative Pretrained Transformer) training,[],Python,2020-08-17T07:08:48Z,2025-12-10T03:49:11Z,True,['mingpt/trainer.py'],True,['tests/test_huggingface_import.py'],79,MIT License
sglang,sgl-project,https://github.com/sgl-project/sglang,21112,3681,SGLang is a fast serving framework for large language models and vision language models.,"['blackwell', 'cuda', 'deepseek', 'deepseek-r1', 'deepseek-v3', 'deepseek-v3-2', 'gpt-oss', 'inference', 'kimi', 'llama', 'llama3', 'llava', 'llm', 'llm-serving', 'moe', 'openai', 'pytorch', 'qwen3', 'transformer', 'vlm']",Python,2024-01-08T04:15:52Z,2025-12-10T05:05:10Z,True,"['docs/references/post_training_integration.md', 'docs/references/post_training_integration.md', 'python/sglang/multimodal_gen/configs/pipeline_configs/flux_finetuned.py', 'python/sglang/srt/constrained/base_grammar_backend.py', 'python/sglang/srt/constrained/llguidance_backend.py']",True,"['.github/workflows/cancel-all-pending-pr-test-runs.yml', '.github/workflows/nightly-test-amd.yml', '.github/workflows/nightly-test-intel.yml', '.github/workflows/nightly-test-npu.yml', '.github/workflows/nightly-test-nvidia.yml']",1661,Apache License 2.0
sentence-transformers,huggingface,https://github.com/huggingface/sentence-transformers,17979,2715,State-of-the-Art Text Embeddings,[],Python,2019-07-24T10:53:51Z,2025-12-10T04:42:17Z,True,"['docs/cross_encoder/pretrained_models.md', 'docs/cross_encoder/training/examples.rst', 'docs/cross_encoder/training_overview.md', 'docs/cross_encoder/training_overview.md', 'docs/img/adaptive_pre-training.png']",True,"['.github/workflows/tests.yml', 'docs/img/backends_benchmark_cpu.png', 'docs/img/backends_benchmark_gpu.png', 'docs/img/ce_backends_benchmark_cpu.png', 'docs/img/ce_backends_benchmark_gpu.png']",1339,Apache License 2.0
trl,huggingface,https://github.com/huggingface/trl,16587,2342,Train transformer language models with reinforcement learning.,[],Python,2020-03-27T10:54:55Z,2025-12-10T03:17:17Z,True,"['.github/issue_template/new-trainer-addition.yml', 'docs/source/bco_trainer.md', 'docs/source/cpo_trainer.md', 'docs/source/distributing_training.md', 'docs/source/dpo_trainer.md']",True,"['.github/workflows/slow-tests.yml', '.github/workflows/tests-experimental.yml', '.github/workflows/tests.yml', '.github/workflows/tests_latest.yml', 'tests/__init__.py']",602,Apache License 2.0
flow-forecast,AIStream-Peelout,https://github.com/AIStream-Peelout/flow-forecast,2260,303,"Deep learning PyTorch library for time series forecasting, classification, and anomaly detection (originally for flood forecasting).","['anomaly-detection', 'deep-learning', 'deep-neural-networks', 'forecasting', 'hacktoberfest', 'lstm', 'pytorch', 'state-of-the-art-models', 'time-series', 'time-series-analysis', 'time-series-forecasting', 'time-series-regression', 'transfer-learning', 'transformer']",Python,2019-08-15T17:02:09Z,2025-12-05T04:31:18Z,True,"['docs/source/long_train.rst', 'docs/source/pytorch_training.rst', 'docs/source/train_da.rst', 'docs/source/train_da.rst', 'docs/source/trainer.rst']",True,"['tests/24_may_202202_25pm_1.json', 'tests/__init__.py', 'tests/auto_encoder.json', 'tests/classification_test.json', 'tests/config.json']",109,GNU General Public License v3.0
MaskDINO,IDEA-Research,https://github.com/IDEA-Research/MaskDINO,1457,149,"[CVPR 2023] Official implementation of the paper ""Mask DINO: Towards A Unified Transformer-based Framework for Object Detection and Segmentation""","['instance-segmentation', 'object-detection', 'panoptic-segmentation', 'semantic-segmentation']",Python,2022-06-06T16:02:01Z,2025-12-09T16:10:49Z,True,"['tools/convert-pretrained-swin-model-to-d2.py', 'train_net.py', 'train_net.py']",True,"['maskdino/modeling/pixel_decoder/ops/test.py', 'maskdino/test_time_augmentation.py', 'tools/evaluate_coco_boundary_ap.py', 'tools/evaluate_pq_for_semantic_segmentation.py']",64,Apache License 2.0
Retinexformer,caiyuanhao1998,https://github.com/caiyuanhao1998/Retinexformer,1327,109,"""Retinexformer: One-stage Retinex-based Transformer for Low-light Image Enhancement"" (ICCV 2023) & (NTIRE 2024 Runner-Up)","['basicsr', 'detection', 'iccv2023', 'image-restoration', 'low-light-enhance', 'low-light-enhancement', 'low-light-enhancer', 'low-light-image-enhancement', 'low-light-vision', 'nighttime-enhancement', 'ntire', 'object-detection', 'transformer']",Python,2023-07-15T10:53:06Z,2025-12-10T01:46:13Z,True,"['basicsr/data/meta_info/meta_info_vimeo90k_train_gt.txt', 'basicsr/data/meta_info/meta_info_vimeo90k_train_gt.txt', 'basicsr/train.py', 'basicsr/train.py', 'train_multigpu.sh']",True,"['enhancement/test_from_dataset.py', 'basicsr/data/meta_info/meta_info_reds4_test_gt.txt', 'basicsr/data/meta_info/meta_info_redsofficial4_test_gt.txt', 'basicsr/data/meta_info/meta_info_redsval_official_test_gt.txt', 'basicsr/data/meta_info/meta_info_vimeo90k_test_gt.txt']",2,MIT License
detoxify,unitaryai,https://github.com/unitaryai/detoxify,1151,135,"Trained models & code to predict toxic comments on all 3 Jigsaw Toxic Comment Challenges. Built using âš¡ Pytorch Lightning and ðŸ¤— Transformers. For access to our API, please email us at contact@unitary.ai.","['bert', 'bert-model', 'hate-speech', 'hate-speech-detection', 'hatespeech', 'huggingface', 'huggingface-transformers', 'kaggle-competition', 'nlp', 'pytorch-lightning', 'sentence-classification', 'toxic-comment-classification', 'toxic-comments', 'toxicity', 'toxicity-classification']",Python,2020-09-23T15:24:21Z,2025-12-09T12:10:22Z,True,"['tests/dummy_data/jigsaw-toxic-comment-classification-challenge/train.csv', 'tests/test_trainer.py', 'train.py', 'train.py']",True,"['.github/workflows/ci-testing.yml', 'tests/__init__.py', 'tests/dummy_data/jigsaw-toxic-comment-classification-challenge/test.csv', 'tests/dummy_data/jigsaw-toxic-comment-classification-challenge/train.csv', 'tests/requirements.txt']",38,Apache License 2.0
