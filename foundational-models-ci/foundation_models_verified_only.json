[
  {
    "name": "transformers",
    "owner": "huggingface",
    "url": "https://github.com/huggingface/transformers",
    "stars": 153668,
    "forks": 31358,
    "description": "\ud83e\udd17 Transformers: the model-definition framework for state-of-the-art machine learning models in text, vision, audio, and multimodal models, for both inference and training. ",
    "topics": [
      "audio",
      "deep-learning",
      "deepseek",
      "gemma",
      "glm",
      "hacktoberfest",
      "llm",
      "machine-learning",
      "model-hub",
      "natural-language-processing",
      "nlp",
      "pretrained-models",
      "python",
      "pytorch",
      "pytorch-transformers",
      "qwen",
      "speech-recognition",
      "transformer",
      "vlm"
    ],
    "language": "Python",
    "created_at": "2018-10-29T13:56:00Z",
    "updated_at": "2025-12-10T05:13:19Z",
    "has_training": true,
    "training_files_sample": [
      "docs/source/ar/trainer.md",
      "docs/source/ar/training.md",
      "docs/source/de/training.md",
      "docs/source/en/hpo_train.md",
      "docs/source/en/internal/trainer_utils.md"
    ],
    "has_testing": true,
    "testing_files_sample": [
      ".circleci/parse_test_outputs.py",
      ".github/workflows/benchmark_v2.yml",
      ".github/workflows/benchmark_v2_a10_caller.yml",
      ".github/workflows/benchmark_v2_mi325_caller.yml",
      ".github/workflows/check_failed_tests.yml"
    ],
    "open_issues": 2142,
    "license": "Apache License 2.0"
  },
  {
    "name": "pytorch-image-models",
    "owner": "huggingface",
    "url": "https://github.com/huggingface/pytorch-image-models",
    "stars": 35974,
    "forks": 5082,
    "description": "The largest collection of PyTorch image encoders / backbones. Including train, eval, inference, export scripts, and pretrained weights -- ResNet, ResNeXT, EfficientNet, NFNet, Vision Transformer (ViT), MobileNetV4, MobileNet-V3 & V2, RegNet, DPN, CSPNet, Swin Transformer, MaxViT, CoAtNet, ConvNeXt, and more",
    "topics": [
      "augmix",
      "convnext",
      "distributed-training",
      "efficientnet",
      "image-classification",
      "imagenet",
      "maxvit",
      "mixnet",
      "mobile-deep-learning",
      "mobilenet-v2",
      "mobilenetv3",
      "nfnets",
      "normalization-free-training",
      "optimizer",
      "pretrained-models",
      "pretrained-weights",
      "pytorch",
      "randaugment",
      "resnet",
      "vision-transformer-models"
    ],
    "language": "Python",
    "created_at": "2019-02-02T05:51:12Z",
    "updated_at": "2025-12-10T04:56:40Z",
    "has_training": true,
    "training_files_sample": [
      "distributed_train.sh",
      "hfdocs/source/training_script.mdx",
      "hfdocs/source/training_script.mdx",
      "results/benchmark-train-amp-nchw-pt112-cu113-rtx3090.csv",
      "results/benchmark-train-amp-nhwc-pt112-cu113-rtx3090.csv"
    ],
    "has_testing": true,
    "testing_files_sample": [
      ".github/workflows/tests.yml",
      "tests/__init__.py",
      "tests/test_layers.py",
      "tests/test_layers_drop.py",
      "tests/test_layers_pool.py"
    ],
    "open_issues": 72,
    "license": "Apache License 2.0"
  },
  {
    "name": "mmdetection",
    "owner": "open-mmlab",
    "url": "https://github.com/open-mmlab/mmdetection",
    "stars": 32143,
    "forks": 9828,
    "description": "OpenMMLab Detection Toolbox and Benchmark",
    "topics": [
      "cascade-rcnn",
      "convnext",
      "detr",
      "fast-rcnn",
      "faster-rcnn",
      "glip",
      "grounding-dino",
      "instance-segmentation",
      "mask-rcnn",
      "object-detection",
      "panoptic-segmentation",
      "pytorch",
      "retinanet",
      "rtmdet",
      "semisupervised-learning",
      "ssd",
      "swin-transformer",
      "transformer",
      "vision-transformer",
      "yolo"
    ],
    "language": "Python",
    "created_at": "2018-08-22T07:06:06Z",
    "updated_at": "2025-12-09T13:47:45Z",
    "has_training": true,
    "training_files_sample": [
      ".dev_scripts/batch_train_list.txt",
      ".dev_scripts/batch_train_list.txt",
      ".dev_scripts/benchmark_train.py",
      ".dev_scripts/benchmark_train.py",
      ".dev_scripts/benchmark_train_models.txt"
    ],
    "has_testing": true,
    "testing_files_sample": [
      ".circleci/test.yml",
      ".dev_scripts/batch_test_list.py",
      ".dev_scripts/benchmark_filter.py",
      ".dev_scripts/benchmark_full_models.txt",
      ".dev_scripts/benchmark_inference_fps.py"
    ],
    "open_issues": 1944,
    "license": "Apache License 2.0"
  },
  {
    "name": "vit-pytorch",
    "owner": "lucidrains",
    "url": "https://github.com/lucidrains/vit-pytorch",
    "stars": 24616,
    "forks": 3459,
    "description": "Implementation of Vision Transformer, a simple way to achieve SOTA in vision classification with only a single transformer encoder, in Pytorch",
    "topics": [
      "artificial-intelligence",
      "attention-mechanism",
      "computer-vision",
      "image-classification",
      "transformers"
    ],
    "language": "Python",
    "created_at": "2020-10-03T22:47:24Z",
    "updated_at": "2025-12-10T04:25:51Z",
    "has_training": true,
    "training_files_sample": [
      "train_vit_decorr.py",
      "train_vit_decorr.py"
    ],
    "has_testing": true,
    "testing_files_sample": [
      ".github/workflows/python-test.yml",
      "tests/.ds_store",
      "tests/test_vit.py"
    ],
    "open_issues": 142,
    "license": "MIT License"
  },
  {
    "name": "minGPT",
    "owner": "karpathy",
    "url": "https://github.com/karpathy/minGPT",
    "stars": 23117,
    "forks": 3029,
    "description": "A minimal PyTorch re-implementation of the OpenAI GPT (Generative Pretrained Transformer) training",
    "topics": [],
    "language": "Python",
    "created_at": "2020-08-17T07:08:48Z",
    "updated_at": "2025-12-10T03:49:11Z",
    "has_training": true,
    "training_files_sample": [
      "mingpt/trainer.py"
    ],
    "has_testing": true,
    "testing_files_sample": [
      "tests/test_huggingface_import.py"
    ],
    "open_issues": 79,
    "license": "MIT License"
  },
  {
    "name": "sglang",
    "owner": "sgl-project",
    "url": "https://github.com/sgl-project/sglang",
    "stars": 21112,
    "forks": 3681,
    "description": "SGLang is a fast serving framework for large language models and vision language models.",
    "topics": [
      "blackwell",
      "cuda",
      "deepseek",
      "deepseek-r1",
      "deepseek-v3",
      "deepseek-v3-2",
      "gpt-oss",
      "inference",
      "kimi",
      "llama",
      "llama3",
      "llava",
      "llm",
      "llm-serving",
      "moe",
      "openai",
      "pytorch",
      "qwen3",
      "transformer",
      "vlm"
    ],
    "language": "Python",
    "created_at": "2024-01-08T04:15:52Z",
    "updated_at": "2025-12-10T05:05:10Z",
    "has_training": true,
    "training_files_sample": [
      "docs/references/post_training_integration.md",
      "docs/references/post_training_integration.md",
      "python/sglang/multimodal_gen/configs/pipeline_configs/flux_finetuned.py",
      "python/sglang/srt/constrained/base_grammar_backend.py",
      "python/sglang/srt/constrained/llguidance_backend.py"
    ],
    "has_testing": true,
    "testing_files_sample": [
      ".github/workflows/cancel-all-pending-pr-test-runs.yml",
      ".github/workflows/nightly-test-amd.yml",
      ".github/workflows/nightly-test-intel.yml",
      ".github/workflows/nightly-test-npu.yml",
      ".github/workflows/nightly-test-nvidia.yml"
    ],
    "open_issues": 1661,
    "license": "Apache License 2.0"
  },
  {
    "name": "sentence-transformers",
    "owner": "huggingface",
    "url": "https://github.com/huggingface/sentence-transformers",
    "stars": 17979,
    "forks": 2715,
    "description": "State-of-the-Art Text Embeddings",
    "topics": [],
    "language": "Python",
    "created_at": "2019-07-24T10:53:51Z",
    "updated_at": "2025-12-10T04:42:17Z",
    "has_training": true,
    "training_files_sample": [
      "docs/cross_encoder/pretrained_models.md",
      "docs/cross_encoder/training/examples.rst",
      "docs/cross_encoder/training_overview.md",
      "docs/cross_encoder/training_overview.md",
      "docs/img/adaptive_pre-training.png"
    ],
    "has_testing": true,
    "testing_files_sample": [
      ".github/workflows/tests.yml",
      "docs/img/backends_benchmark_cpu.png",
      "docs/img/backends_benchmark_gpu.png",
      "docs/img/ce_backends_benchmark_cpu.png",
      "docs/img/ce_backends_benchmark_gpu.png"
    ],
    "open_issues": 1339,
    "license": "Apache License 2.0"
  },
  {
    "name": "trl",
    "owner": "huggingface",
    "url": "https://github.com/huggingface/trl",
    "stars": 16587,
    "forks": 2342,
    "description": "Train transformer language models with reinforcement learning.",
    "topics": [],
    "language": "Python",
    "created_at": "2020-03-27T10:54:55Z",
    "updated_at": "2025-12-10T03:17:17Z",
    "has_training": true,
    "training_files_sample": [
      ".github/issue_template/new-trainer-addition.yml",
      "docs/source/bco_trainer.md",
      "docs/source/cpo_trainer.md",
      "docs/source/distributing_training.md",
      "docs/source/dpo_trainer.md"
    ],
    "has_testing": true,
    "testing_files_sample": [
      ".github/workflows/slow-tests.yml",
      ".github/workflows/tests-experimental.yml",
      ".github/workflows/tests.yml",
      ".github/workflows/tests_latest.yml",
      "tests/__init__.py"
    ],
    "open_issues": 602,
    "license": "Apache License 2.0"
  },
  {
    "name": "flow-forecast",
    "owner": "AIStream-Peelout",
    "url": "https://github.com/AIStream-Peelout/flow-forecast",
    "stars": 2260,
    "forks": 303,
    "description": "Deep learning PyTorch library for time series forecasting, classification, and anomaly detection (originally for flood forecasting).",
    "topics": [
      "anomaly-detection",
      "deep-learning",
      "deep-neural-networks",
      "forecasting",
      "hacktoberfest",
      "lstm",
      "pytorch",
      "state-of-the-art-models",
      "time-series",
      "time-series-analysis",
      "time-series-forecasting",
      "time-series-regression",
      "transfer-learning",
      "transformer"
    ],
    "language": "Python",
    "created_at": "2019-08-15T17:02:09Z",
    "updated_at": "2025-12-05T04:31:18Z",
    "has_training": true,
    "training_files_sample": [
      "docs/source/long_train.rst",
      "docs/source/pytorch_training.rst",
      "docs/source/train_da.rst",
      "docs/source/train_da.rst",
      "docs/source/trainer.rst"
    ],
    "has_testing": true,
    "testing_files_sample": [
      "tests/24_may_202202_25pm_1.json",
      "tests/__init__.py",
      "tests/auto_encoder.json",
      "tests/classification_test.json",
      "tests/config.json"
    ],
    "open_issues": 109,
    "license": "GNU General Public License v3.0"
  },
  {
    "name": "MaskDINO",
    "owner": "IDEA-Research",
    "url": "https://github.com/IDEA-Research/MaskDINO",
    "stars": 1457,
    "forks": 149,
    "description": "[CVPR 2023] Official implementation of the paper \"Mask DINO: Towards A Unified Transformer-based Framework for Object Detection and Segmentation\"",
    "topics": [
      "instance-segmentation",
      "object-detection",
      "panoptic-segmentation",
      "semantic-segmentation"
    ],
    "language": "Python",
    "created_at": "2022-06-06T16:02:01Z",
    "updated_at": "2025-12-09T16:10:49Z",
    "has_training": true,
    "training_files_sample": [
      "tools/convert-pretrained-swin-model-to-d2.py",
      "train_net.py",
      "train_net.py"
    ],
    "has_testing": true,
    "testing_files_sample": [
      "maskdino/modeling/pixel_decoder/ops/test.py",
      "maskdino/test_time_augmentation.py",
      "tools/evaluate_coco_boundary_ap.py",
      "tools/evaluate_pq_for_semantic_segmentation.py"
    ],
    "open_issues": 64,
    "license": "Apache License 2.0"
  },
  {
    "name": "Retinexformer",
    "owner": "caiyuanhao1998",
    "url": "https://github.com/caiyuanhao1998/Retinexformer",
    "stars": 1327,
    "forks": 109,
    "description": "\"Retinexformer: One-stage Retinex-based Transformer for Low-light Image Enhancement\" (ICCV 2023) & (NTIRE 2024 Runner-Up)",
    "topics": [
      "basicsr",
      "detection",
      "iccv2023",
      "image-restoration",
      "low-light-enhance",
      "low-light-enhancement",
      "low-light-enhancer",
      "low-light-image-enhancement",
      "low-light-vision",
      "nighttime-enhancement",
      "ntire",
      "object-detection",
      "transformer"
    ],
    "language": "Python",
    "created_at": "2023-07-15T10:53:06Z",
    "updated_at": "2025-12-10T01:46:13Z",
    "has_training": true,
    "training_files_sample": [
      "basicsr/data/meta_info/meta_info_vimeo90k_train_gt.txt",
      "basicsr/data/meta_info/meta_info_vimeo90k_train_gt.txt",
      "basicsr/train.py",
      "basicsr/train.py",
      "train_multigpu.sh"
    ],
    "has_testing": true,
    "testing_files_sample": [
      "enhancement/test_from_dataset.py",
      "basicsr/data/meta_info/meta_info_reds4_test_gt.txt",
      "basicsr/data/meta_info/meta_info_redsofficial4_test_gt.txt",
      "basicsr/data/meta_info/meta_info_redsval_official_test_gt.txt",
      "basicsr/data/meta_info/meta_info_vimeo90k_test_gt.txt"
    ],
    "open_issues": 2,
    "license": "MIT License"
  },
  {
    "name": "detoxify",
    "owner": "unitaryai",
    "url": "https://github.com/unitaryai/detoxify",
    "stars": 1151,
    "forks": 135,
    "description": "Trained models & code to predict toxic comments on all 3 Jigsaw Toxic Comment Challenges. Built using \u26a1 Pytorch Lightning and \ud83e\udd17 Transformers. For access to our API, please email us at contact@unitary.ai.",
    "topics": [
      "bert",
      "bert-model",
      "hate-speech",
      "hate-speech-detection",
      "hatespeech",
      "huggingface",
      "huggingface-transformers",
      "kaggle-competition",
      "nlp",
      "pytorch-lightning",
      "sentence-classification",
      "toxic-comment-classification",
      "toxic-comments",
      "toxicity",
      "toxicity-classification"
    ],
    "language": "Python",
    "created_at": "2020-09-23T15:24:21Z",
    "updated_at": "2025-12-09T12:10:22Z",
    "has_training": true,
    "training_files_sample": [
      "tests/dummy_data/jigsaw-toxic-comment-classification-challenge/train.csv",
      "tests/test_trainer.py",
      "train.py",
      "train.py"
    ],
    "has_testing": true,
    "testing_files_sample": [
      ".github/workflows/ci-testing.yml",
      "tests/__init__.py",
      "tests/dummy_data/jigsaw-toxic-comment-classification-challenge/test.csv",
      "tests/dummy_data/jigsaw-toxic-comment-classification-challenge/train.csv",
      "tests/requirements.txt"
    ],
    "open_issues": 38,
    "license": "Apache License 2.0"
  }
]